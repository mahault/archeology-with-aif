{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0defuTzXqw5u",
        "outputId": "561a9bcc-acae-472a-8399-7f321e3e9e54"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Parameters\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "num_agents = 5          # Number of agents\n",
        "num_timesteps = 50      # Number of time steps in the simulation\n",
        "num_artifacts = 100     # Number of potential artifacts to be distributed\n",
        "\n",
        "# Initialize environment and agent beliefs\n",
        "environment = np.zeros(num_artifacts)\n",
        "agent_beliefs = np.random.rand(num_agents, num_artifacts)  # Initial random beliefs\n",
        "\n",
        "# Define utility and expected utility for calculating valence\n",
        "def calculate_utility(state, action):\n",
        "    return np.sum(state * action)\n",
        "\n",
        "def calculate_expected_utility(belief):\n",
        "    return np.mean(belief)\n",
        "\n",
        "# Variational free energy function (simplified)\n",
        "def variational_free_energy(state, observation, belief):\n",
        "    kl_divergence = np.sum(belief * np.log(belief / (state + 1e-10)))\n",
        "    log_evidence = np.sum(observation * np.log(state + 1e-10))\n",
        "    return kl_divergence - log_evidence\n",
        "\n",
        "# Policy selection based on expected free energy\n",
        "def select_policy(agent_belief, state):\n",
        "    best_action = None\n",
        "    min_free_energy = float('inf')\n",
        "    for action in np.eye(num_artifacts):  # Each action corresponds to focusing on one artifact\n",
        "        expected_state = agent_belief * action\n",
        "        free_energy = variational_free_energy(state, expected_state, agent_belief)\n",
        "        if free_energy < min_free_energy:\n",
        "            min_free_energy = free_energy\n",
        "            best_action = action\n",
        "    return best_action\n",
        "\n",
        "# Simulation loop\n",
        "for t in range(num_timesteps):\n",
        "    print(f\"Time step {t + 1}/{num_timesteps}\")\n",
        "\n",
        "    for i in range(num_agents):\n",
        "        # Select a policy (action) for the agent\n",
        "        action = select_policy(agent_beliefs[i], environment)\n",
        "\n",
        "        # Update environment based on the action (niche construction)\n",
        "        environment += action\n",
        "\n",
        "        # Update agent's belief (belief updating)\n",
        "        observation = environment + np.random.normal(0, 0.1, num_artifacts)  # Observed state with some noise\n",
        "        agent_beliefs[i] += 0.1 * (observation - agent_beliefs[i])  # Simple update rule\n",
        "\n",
        "        # Calculate valence\n",
        "        utility = calculate_utility(environment, action)\n",
        "        expected_utility = calculate_expected_utility(agent_beliefs[i])\n",
        "        valence = utility - expected_utility\n",
        "\n",
        "        # Print the results\n",
        "        print(f\"Agent {i + 1} selected action {np.argmax(action)} with valence {valence:.2f}\")\n",
        "\n",
        "    # Visualize the environment and agent beliefs\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(environment, label='Environment State', color='black', linewidth=2)\n",
        "    for i in range(num_agents):\n",
        "        plt.plot(agent_beliefs[i], label=f'Agent {i + 1} Belief')\n",
        "    plt.title(f\"Environment and Agent Beliefs at Time Step {t + 1}\")\n",
        "    plt.xlabel(\"Artifact Index\")\n",
        "    plt.ylabel(\"Belief / State Value\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Final environment state\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(environment, label='Final Environment State', color='black', linewidth=2)\n",
        "plt.title(\"Final Environment State\")\n",
        "plt.xlabel(\"Artifact Index\")\n",
        "plt.ylabel(\"State Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxO3gNAWIUQN"
      },
      "source": [
        "Valence Calculation:\n",
        "\n",
        "Valence is calculated as the difference between the expected utility (what the agent hoped to achieve) and the actual utility (what the agent actually achieved).\n",
        "If an agent expects to find food (high expected utility) but does not (low actual utility), the valence will be negative. Conversely, if the agent finds food when expected, the valence will be positive.\n",
        "Shared Protentions:\n",
        "\n",
        "Shared protentions are implemented as a grid (self.shared_protentions) that represents the cumulative learned scripts or expectations based on previous experiences.\n",
        "After each action, the agent updates this grid based on the valence it experienced. Positive valence (successful actions) strengthens the expectation that similar actions will lead to good outcomes in the future.\n",
        "Script Learning:\n",
        "\n",
        "Agents update their shared protentions after each action, adjusting their future behavior based on the actions and outcomes of both themselves and earlier agents.\n",
        "Environmental Interaction:\n",
        "\n",
        "The rest of the simulation remains similar, with agents interacting with the environment, leaving traces, and learning from the traces left by others. However, now their actions are guided by not only minimizing free energy but also by the valence of their previous experiences and the shared protentions they have developed.\n",
        "Summary\n",
        "This revised simulation now includes:\n",
        "\n",
        "Valence: The emotional response of agents to their outcomes, influencing their future actions.\n",
        "Shared Protentions: Expectations about future outcomes based on previous experiences, which are updated dynamically as agents learn from their environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nJqq5akWqx8V",
        "outputId": "0eca62fb-02b0-4402-90ac-80caaffe99c1"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Parameters\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "grid_size = (10, 10)\n",
        "num_waves = 10\n",
        "agents_per_wave = 3\n",
        "agent_lifetime = 2\n",
        "trace_decay = 0.9\n",
        "\n",
        "# Initialize the environment\n",
        "environment = np.zeros(grid_size)\n",
        "food_positions = [(2, 3), (7, 8), (5, 5)]\n",
        "for pos in food_positions:\n",
        "    environment[pos] = 1\n",
        "\n",
        "# Function to plot the environment\n",
        "def plot_environment(env, title):\n",
        "    plt.imshow(env, cmap='hot', interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Agent class definition\n",
        "class Agent:\n",
        "    def __init__(self, position, grid_size):\n",
        "        self.position = position\n",
        "        self.grid_size = grid_size\n",
        "        self.belief = np.zeros(grid_size)\n",
        "        self.expected_utility = 0\n",
        "        self.shared_protentions = np.zeros(grid_size)  # Represents learned scripts\n",
        "\n",
        "    def observe(self, environment):\n",
        "        return environment\n",
        "\n",
        "    def update_belief(self, observation):\n",
        "        likelihood = observation\n",
        "        prior = self.belief\n",
        "        self.belief = likelihood * prior\n",
        "        self.belief /= (np.sum(self.belief) + 1e-10)\n",
        "\n",
        "    def calculate_free_energy(self, observation):\n",
        "        q_theta = self.belief\n",
        "        p_theta_given_o = observation / (np.sum(observation) + 1e-10)\n",
        "        kl_divergence = np.sum(q_theta * np.log(q_theta / (p_theta_given_o + 1e-10) + 1e-10))\n",
        "        log_p_o = np.sum(np.log(p_theta_given_o + 1e-10))\n",
        "        free_energy = kl_divergence - log_p_o\n",
        "        return free_energy\n",
        "\n",
        "    def calculate_valence(self, actual_utility):\n",
        "        valence = actual_utility - self.expected_utility\n",
        "        return valence\n",
        "\n",
        "    def update_shared_protentions(self, action, valence):\n",
        "        # Update shared protentions based on the action taken and the valence experienced\n",
        "        x, y = self.position\n",
        "        self.shared_protentions[x, y] += valence\n",
        "\n",
        "    def select_action(self):\n",
        "        min_free_energy = float('inf')\n",
        "        best_move = None\n",
        "        moves = ['up', 'down', 'left', 'right']\n",
        "        for move in moves:\n",
        "            simulated_observation = self.simulate_move(move)\n",
        "            free_energy = self.calculate_free_energy(simulated_observation)\n",
        "            if free_energy < min_free_energy:\n",
        "                min_free_energy = free_energy\n",
        "                best_move = move\n",
        "        return best_move\n",
        "\n",
        "    def simulate_move(self, move):\n",
        "        x, y = self.position\n",
        "        if move == 'up' and x > 0:\n",
        "            x -= 1\n",
        "        elif move == 'down' and x < self.grid_size[0] - 1:\n",
        "            x += 1\n",
        "        elif move == 'left' and y > 0:\n",
        "            y -= 1\n",
        "        elif move == 'right' and y < self.grid_size[1] - 1:\n",
        "            y += 1\n",
        "        simulated_position = (x, y)\n",
        "        simulated_observation = np.zeros_like(self.belief)\n",
        "        simulated_observation[simulated_position] = 1\n",
        "        return simulated_observation\n",
        "\n",
        "    def move(self, action):\n",
        "        x, y = self.position\n",
        "        if action == 'up' and x > 0:\n",
        "            x -= 1\n",
        "        elif action == 'down' and x < self.grid_size[0] - 1:\n",
        "            x += 1\n",
        "        elif action == 'left' and y > 0:\n",
        "            y -= 1\n",
        "        elif action == 'right' and y < self.grid_size[1] - 1:\n",
        "            y += 1\n",
        "        self.position = (x, y)\n",
        "\n",
        "    def leave_trace(self, environment):\n",
        "        x, y = self.position\n",
        "        environment[x, y] += 0.5\n",
        "\n",
        "# Simulation loop\n",
        "for wave in range(num_waves):\n",
        "    print(f\"Wave {wave + 1}\")\n",
        "    agents = [Agent((np.random.randint(grid_size[0]), np.random.randint(grid_size[1])), grid_size)\n",
        "              for _ in range(agents_per_wave)]\n",
        "\n",
        "    for timestep in range(agent_lifetime + 1):\n",
        "        print(f\"  Timestep {timestep + 1}\")\n",
        "        for agent in agents:\n",
        "            observation = agent.observe(environment)\n",
        "            agent.update_belief(observation)\n",
        "            action = agent.select_action()\n",
        "            agent.move(action)\n",
        "            agent.leave_trace(environment)\n",
        "\n",
        "            # Calculate utility (e.g., finding food)\n",
        "            if environment[agent.position] == 1:\n",
        "                actual_utility = 1  # Food found\n",
        "                print(f\"    Agent at {agent.position} found food!\")\n",
        "            else:\n",
        "                actual_utility = 0\n",
        "\n",
        "            # Calculate valence and update shared protentions\n",
        "            valence = agent.calculate_valence(actual_utility)\n",
        "            agent.update_shared_protentions(action, valence)\n",
        "\n",
        "        environment *= trace_decay\n",
        "        plot_environment(environment, f\"Environment after Wave {wave + 1}, Timestep {timestep + 1}\")\n",
        "\n",
        "print(\"Simulation complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeCq5tfIJHwl"
      },
      "source": [
        "Here the food moves every two timesteps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N5vwDusgynDh",
        "outputId": "f7c7201a-ee7f-4c6e-c0b5-cb2a62689ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wave 1\n",
            "  Timestep 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Timestep 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Timestep 3\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wave 2\n",
            "  Timestep 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Timestep 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Timestep 3\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wave 3\n",
            "  Timestep 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Timestep 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Timestep 3\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulation complete.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "grid_size = (10, 10)\n",
        "num_waves = 3\n",
        "agents_per_wave = 3\n",
        "agent_lifetime = 2\n",
        "trace_decay = 0.9\n",
        "food_move_interval = 2  # Move food every 2 timesteps\n",
        "\n",
        "# Initialize the environment\n",
        "environment = np.zeros(grid_size)\n",
        "food_position = (2, 3)  # Initial position of the food\n",
        "environment[food_position] = 1\n",
        "\n",
        "def plot_environment(env, title):\n",
        "    plt.imshow(env, cmap='hot', interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def move_food(environment, current_position):\n",
        "    x, y = current_position\n",
        "    moves = ['up', 'down', 'left', 'right']\n",
        "    move = np.random.choice(moves)\n",
        "\n",
        "    if move == 'up' and x > 0:\n",
        "        x -= 1\n",
        "    elif move == 'down' and x < grid_size[0] - 1:\n",
        "        x += 1\n",
        "    elif move == 'left' and y > 0:\n",
        "        y -= 1\n",
        "    elif move == 'right' and y < grid_size[1] - 1:\n",
        "        y += 1\n",
        "\n",
        "    new_position = (x, y)\n",
        "    environment[current_position] = 0  # Remove food from old position\n",
        "    environment[new_position] = 1  # Place food in new position\n",
        "    return new_position\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, position, grid_size):\n",
        "        self.position = position\n",
        "        self.grid_size = grid_size\n",
        "        self.belief = np.zeros(grid_size)\n",
        "        self.expected_utility = 0\n",
        "        self.shared_protentions = np.zeros(grid_size)\n",
        "\n",
        "    def observe(self, environment):\n",
        "        return environment\n",
        "\n",
        "    def update_belief(self, observation):\n",
        "        likelihood = observation\n",
        "        prior = self.belief\n",
        "        self.belief = likelihood * prior\n",
        "        self.belief /= (np.sum(self.belief) + 1e-10)\n",
        "\n",
        "    def calculate_free_energy(self, observation):\n",
        "        q_theta = self.belief\n",
        "        p_theta_given_o = observation / (np.sum(observation) + 1e-10)\n",
        "        kl_divergence = np.sum(q_theta * np.log(q_theta / (p_theta_given_o + 1e-10) + 1e-10))\n",
        "        log_p_o = np.sum(np.log(p_theta_given_o + 1e-10))\n",
        "        free_energy = kl_divergence - log_p_o\n",
        "        return free_energy\n",
        "\n",
        "    def calculate_valence(self, actual_utility):\n",
        "        valence = actual_utility - self.expected_utility\n",
        "        return valence\n",
        "\n",
        "    def update_shared_protentions(self, action, valence):\n",
        "        x, y = self.position\n",
        "        self.shared_protentions[x, y] += valence\n",
        "\n",
        "    def select_action(self):\n",
        "        min_free_energy = float('inf')\n",
        "        best_move = None\n",
        "        moves = ['up', 'down', 'left', 'right']\n",
        "        for move in moves:\n",
        "            simulated_observation = self.simulate_move(move)\n",
        "            free_energy = self.calculate_free_energy(simulated_observation)\n",
        "            if free_energy < min_free_energy:\n",
        "                min_free_energy = free_energy\n",
        "                best_move = move\n",
        "        return best_move\n",
        "\n",
        "    def simulate_move(self, move):\n",
        "        x, y = self.position\n",
        "        if move == 'up' and x > 0:\n",
        "            x -= 1\n",
        "        elif move == 'down' and x < self.grid_size[0] - 1:\n",
        "            x += 1\n",
        "        elif move == 'left' and y > 0:\n",
        "            y -= 1\n",
        "        elif move == 'right' and y < self.grid_size[1] - 1:\n",
        "            y += 1\n",
        "        simulated_position = (x, y)\n",
        "        simulated_observation = np.zeros_like(self.belief)\n",
        "        simulated_observation[simulated_position] = 1\n",
        "        return simulated_observation\n",
        "\n",
        "    def move(self, action):\n",
        "        x, y = self.position\n",
        "        if action == 'up' and x > 0:\n",
        "            x -= 1\n",
        "        elif action == 'down' and x < self.grid_size[0] - 1:\n",
        "            x += 1\n",
        "        elif action == 'left' and y > 0:\n",
        "            y -= 1\n",
        "        elif action == 'right' and y < self.grid_size[1] - 1:\n",
        "            y += 1\n",
        "        self.position = (x, y)\n",
        "\n",
        "    def leave_trace(self, environment):\n",
        "        x, y = self.position\n",
        "        environment[x, y] += 0.5\n",
        "\n",
        "# Simulation loop\n",
        "for wave in range(num_waves):\n",
        "    print(f\"Wave {wave + 1}\")\n",
        "    agents = [Agent((np.random.randint(grid_size[0]), np.random.randint(grid_size[1])), grid_size)\n",
        "              for _ in range(agents_per_wave)]\n",
        "\n",
        "    for timestep in range(agent_lifetime + 1):\n",
        "        print(f\"  Timestep {timestep + 1}\")\n",
        "        for agent in agents:\n",
        "            observation = agent.observe(environment)\n",
        "            agent.update_belief(observation)\n",
        "            action = agent.select_action()\n",
        "            agent.move(action)\n",
        "            agent.leave_trace(environment)\n",
        "\n",
        "            if environment[agent.position] == 1:\n",
        "                actual_utility = 1  # Food found\n",
        "                print(f\"    Agent at {agent.position} found food!\")\n",
        "            else:\n",
        "                actual_utility = 0\n",
        "\n",
        "            valence = agent.calculate_valence(actual_utility)\n",
        "            agent.update_shared_protentions(action, valence)\n",
        "\n",
        "        # Move the food every `food_move_interval` timesteps\n",
        "        if timestep % food_move_interval == 0 and timestep > 0:\n",
        "            food_position = move_food(environment, food_position)\n",
        "\n",
        "        environment *= trace_decay\n",
        "        plot_environment(environment, f\"Environment after Wave {wave + 1}, Timestep {timestep + 1}\")\n",
        "\n",
        "print(\"Simulation complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl7E1fY8LUH-"
      },
      "source": [
        "Here we can see the agents in blue, and they're supposed to leave a trace in the env only if they find food"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdinwOu-P44A"
      },
      "source": [
        "Here we added some checking code, but still not working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYFhY5-Dnld9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cItoYrMUyFa",
        "outputId": "23b64c0e-595a-4029-898e-a830c644a62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvMitzdkIhny",
        "outputId": "ed2d0a7f-3c9a-4b16-abf0-50a40346fe57"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'env' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Mahault/OneDrive/Desktop/projects/mathmodel/env/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install python3.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNLRpZeCXdjH",
        "outputId": "34190809-3a2c-4817-b829-311d4d06bfbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package pip3.11\n",
            "E: Couldn't find any package by glob 'pip3.11'\n",
            "E: Couldn't find any package by regex 'pip3.11'\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install pip3.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia-ZFq4GLCM5",
        "outputId": "587df9b5-0e16-4057-ab22-2cf77899a8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.9\n"
          ]
        }
      ],
      "source": [
        "!py -3.11 --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X26xmzazL8av",
        "outputId": "895d4cd6-4217-416b-9bbc-4357db7d8ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ],
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5XZz-1zL8c4",
        "outputId": "d8f4ba71-c51b-49b0-fd5d-9872c8483ba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "update-alternatives: using /usr/bin/python3.11 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ],
      "source": [
        " !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka6v5p-0NuJT",
        "outputId": "02feef2b-59ff-4629-e9f6-50d26e846f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.11-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install python3.11-distutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9kzjXphNyt6",
        "outputId": "6cb52d26-a3fa-415b-cf55-46c3f023b5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-74.1.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "Downloading setuptools-74.1.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-24.2 setuptools-74.1.0 wheel-0.44.0\n"
          ]
        }
      ],
      "source": [
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93KL3H2FU1Ez",
        "outputId": "a67ab784-4ba6-4567-88f6-3b869ecbd459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jax in c:\\users\\mahault\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.31)\n",
            "Requirement already satisfied: jaxlib<=0.4.31,>=0.4.30 in c:\\users\\mahault\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax) (0.4.31)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\mahault\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.24 in c:\\users\\mahault\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax) (2.1.0)\n",
            "Requirement already satisfied: opt-einsum in c:\\users\\mahault\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.10 in c:\\users\\mahault\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax) (1.14.1)\n"
          ]
        }
      ],
      "source": [
        "!py -3.11 -m pip install --upgrade jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn9gSB9tUCwU",
        "outputId": "671fe79f-fa61-4faf-f0d5-0a8e11070e97"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'env' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Mahault/OneDrive/Desktop/projects/mathmodel/env/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# prompt: I want to git clone this repo https://github.com/infer-actively/pymdp.git on the branch api_model and then import it\n",
        "\n",
        "# !git clone -b api_model https://github.com/infer-actively/pymdp.git\n",
        "import sys\n",
        "# sys.path.append('/content/pymdp/pymdp/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyQ9MODuGjfc"
      },
      "outputs": [],
      "source": [
        "sys.path.append('/content/pymdp/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_pFUiCTF0_B",
        "outputId": "18823213-dbbf-49d7-89aa-ebb99358ea28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "agent.py  control.py\t     envs\t   __init__.py\tlearning.py  utils.py\n",
            "algos\t  default_models.py  inference.py  jax\t\tmaths.py\n"
          ]
        }
      ],
      "source": [
        "!ls /content/pymdp/pymdp/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlmFOYWQSoEu",
        "outputId": "b69b0719-545a-458d-e618-a614b8488114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting equinox\n",
            "  Downloading equinox-0.11.5-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: jax!=0.4.27,>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from equinox) (0.4.31)\n",
            "Collecting jaxtyping>=0.2.20 (from equinox)\n",
            "  Downloading jaxtyping-0.2.34-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typing-extensions>=4.5.0 (from equinox)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jaxlib<=0.4.31,>=0.4.30 in /usr/local/lib/python3.11/dist-packages (from jax!=0.4.27,>=0.4.13->equinox) (0.4.31)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax!=0.4.27,>=0.4.13->equinox) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from jax!=0.4.27,>=0.4.13->equinox) (2.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax!=0.4.27,>=0.4.13->equinox) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax!=0.4.27,>=0.4.13->equinox) (1.14.1)\n",
            "Collecting typeguard==2.13.3 (from jaxtyping>=0.2.20->equinox)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading equinox-0.11.5-py3-none-any.whl (177 kB)\n",
            "Downloading jaxtyping-0.2.34-py3-none-any.whl (42 kB)\n",
            "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-extensions, typeguard, jaxtyping, equinox\n",
            "Successfully installed equinox-0.11.5 jaxtyping-0.2.34 typeguard-2.13.3 typing-extensions-4.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install equinox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vA7DIzUZHfbM",
        "outputId": "75da83a0-a3f3-46b9-9dbe-6cfb3e885ce1"
      },
      "outputs": [],
      "source": [
        "!py -3.11 -m pip uninstall pymdp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRicTbz-OoJm"
      },
      "outputs": [],
      "source": [
        "!python pymdp --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePin2yySKuq5"
      },
      "source": [
        "import pymdp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "OoBPrvkpRezu",
        "outputId": "40f208de-1f66-4f6c-8b24-97d40d6006ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Timestep 1:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 2:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 3:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 4:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 5:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 6:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 7:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 8:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 9:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 10:\n",
            "Agent location: 6\n",
            "Food location: 5\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "Maximum timesteps reached. Food not found.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 3\n",
        "num_locations = grid_size * grid_size\n",
        "\n",
        "# Possible actions\n",
        "movement_actions = [\"up\", \"down\", \"left\", \"right\"]\n",
        "trace_actions = [\"leave_trace\", \"no_trace\"]\n",
        "\n",
        "\n",
        "def get_visible_locations(agent_location, grid_size, radius=1):\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    visible = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            x, y = agent_x + dx, agent_y + dy\n",
        "            if 0 <= x < grid_size and 0 <= y < grid_size:\n",
        "                visible.append(x * grid_size + y)\n",
        "    return visible\n",
        "\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    return x * grid_size + y\n",
        "\n",
        "\n",
        "# Updated Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"self_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "        },\n",
        "        \"food_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "        },\n",
        "        \"trace_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"trace_location_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"movement\": {\"elements\": movement_actions},\n",
        "        \"trace\": {\"elements\": trace_actions},\n",
        "        \"food_location_action\": {\"elements\": [\"nil\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"self_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "            \"controlled_by\": [\"movement\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"food_location_action\"],\n",
        "        },\n",
        "        \"trace_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"trace_location_state\", \"self_location_state\"],\n",
        "            \"controlled_by\": [\"trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "# Populate A matrices\n",
        "# Self location observation (identity mapping)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"self_location\"][i, i] = 1.0\n",
        "\n",
        "# Food present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        if self_loc == food_loc:\n",
        "            model.A[\"food_present\"][0, self_loc, food_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"food_present\"][1, self_loc, food_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Trace present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for trace_loc in range(num_locations):\n",
        "        if self_loc == trace_loc:\n",
        "            model.A[\"trace_present\"][0, self_loc, trace_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"trace_present\"][1, self_loc, trace_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Populate B matrices\n",
        "# Self movement\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(movement_actions):\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "        model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# Traces update\n",
        "for current_trace in range(num_locations):\n",
        "    for self_loc in range(num_locations):\n",
        "        model.B[\"trace_location_state\"][current_trace, current_trace, self_loc, 0] = 1.0  # Existing trace remains\n",
        "        model.B[\"trace_location_state\"][self_loc, current_trace, self_loc, 1] = 1.0  # New trace is created\n",
        "\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"self_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "model.C[\"food_present\"] = np.array([1.0, 0.0])  # Prefer food present\n",
        "model.C[\"trace_present\"] = np.array([0.5, 0.5])  # Neutral about traces\n",
        "\n",
        "model.D[\"self_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"trace_location_state\"] = np.zeros(num_locations)  # No traces initially\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "traces = np.zeros(num_locations)\n",
        "\n",
        "\n",
        "def run_timestep(agent, agent_location, food_location, traces, previous_movement, previous_trace):\n",
        "    # Generate observations\n",
        "    self_loc_obs = np.zeros(num_locations)\n",
        "    self_loc_obs[agent_location] = 1\n",
        "\n",
        "    food_present_obs = np.zeros(2)\n",
        "    food_present_obs[0 if agent_location == food_location else 1] = 1\n",
        "\n",
        "    trace_present_obs = np.zeros(2)\n",
        "    trace_present_obs[0 if traces[agent_location] > 0 else 1] = 1\n",
        "\n",
        "    observations = [jnp.array(self_loc_obs), jnp.array(food_present_obs), jnp.array(trace_present_obs)]\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    qs_init = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "    # Infer the empirical prior\n",
        "    previous_actions = jnp.array([[movement_actions.index(previous_movement), trace_actions.index(previous_trace), 0]])\n",
        "    prior, _ = agent.infer_empirical_prior(previous_actions, qs_init)\n",
        "\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "\n",
        "    # Infer policies and sample actions\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    movement_action_index, trace_action_index, _ = agent.sample_action(q_pi)[0]\n",
        "    movement_action = movement_actions[movement_action_index]\n",
        "    trace_action = trace_actions[trace_action_index]\n",
        "\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, movement_action, grid_size)\n",
        "\n",
        "    # Update traces\n",
        "    if trace_action == \"leave_trace\":\n",
        "        traces[agent_location] = 1.0\n",
        "\n",
        "    return qs, movement_action, trace_action, new_agent_location, traces\n",
        "\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 10\n",
        "previous_movement = \"up\"\n",
        "previous_trace = \"no_trace\"\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, movement_action, trace_action, agent_location, traces = run_timestep(\n",
        "        agent, agent_location, food_location, traces, previous_movement, previous_trace\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Movement action: {movement_action}\")\n",
        "    print(f\"Trace action: {trace_action}\")\n",
        "    print(f\"Traces: {traces}\")\n",
        "\n",
        "    previous_movement = movement_action\n",
        "    previous_trace = trace_action\n",
        "\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        break\n",
        "\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "KZ7FlwJYiwUs",
        "outputId": "4accf7db-a8dd-4a96-a78c-e0debaf40712"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "vmap was requested to map its argument along axis 0, which implies that its rank should be at least 1, but is only 0 (its shape is ())",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_get_axis_size\u001b[0;34m(name, shape, axis)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-389cce9d12c3>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Infer the agent's and food's locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mqs_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mqs_food\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_get_axis_size\u001b[0;34m(name, shape, axis)\u001b[0m\n\u001b[1;32m   1255\u001b[0m       \u001b[0mmin_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m       \u001b[0;31m# TODO(mattjj): better error message here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   1258\u001b[0m           \u001b[0;34mf\"{name} was requested to map its argument along axis {axis}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m           \u001b[0;34mf\"which implies that its rank should be at least {min_rank}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: vmap was requested to map its argument along axis 0, which implies that its rank should be at least 1, but is only 0 (its shape is ())"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 3\n",
        "\n",
        "# Possible actions\n",
        "actions = [\"up\", \"down\", \"left\", \"right\"]\n",
        "\n",
        "def get_visible_locations(agent_location, radius=1):\n",
        "    \"\"\"\n",
        "    Returns a list of grid locations within a given radius of the agent.\n",
        "\n",
        "    Args:\n",
        "        agent_location: The current location of the agent.\n",
        "        radius: The radius of visibility.\n",
        "\n",
        "    Returns:\n",
        "        A list of visible grid locations.\n",
        "    \"\"\"\n",
        "\n",
        "    visible_locations = []\n",
        "    for i in range(agent_location - radius, agent_location + radius + 1):\n",
        "        for j in range(agent_location - radius, agent_location + radius + 1):\n",
        "            if 0 <= i < grid_size and 0 <= j < grid_size:\n",
        "                visible_locations.append(i * grid_size + j)\n",
        "\n",
        "    return visible_locations\n",
        "\n",
        "# Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"agent_location\": {\n",
        "            \"elements\": range(grid_size * grid_size),\n",
        "            \"depends_on\": [\"agent_location_state\"],\n",
        "        },\n",
        "        \"food_location\": {\n",
        "            \"elements\": range(grid_size * grid_size),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "        },\n",
        "        \"trace_location\": {\n",
        "            \"elements\": range(grid_size * grid_size),\n",
        "            \"depends_on\": [\"traces_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"action\": {\"elements\": actions},\n",
        "        \"nil_food\": {\"elements\": \"none\"},\n",
        "        \"trace\": {\"elements\": [\"yes\", \"no\"]}\n",
        "                 },\n",
        "    \"states\": {\n",
        "        \"agent_location_state\": {\n",
        "            \"elements\": range(grid_size * grid_size),\n",
        "            \"depends_on\": [\"agent_location_state\"],  # Depends on previous location and action,\n",
        "            \"controlled_by\": [\"action\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(grid_size * grid_size),\n",
        "            \"depends_on\": [\"food_location_state\"],  # Food location remains constant\n",
        "            \"controlled_by\": [\"nil_food\"],\n",
        "        },\n",
        "        \"traces_state\": {\n",
        "            \"elements\": range(grid_size * grid_size),\n",
        "            \"depends_on\": [\"traces_state\", \"agent_location_state\"],  # Traces depend on previous traces and agent location\n",
        "            \"controlled_by\": [\"trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(grid_size * grid_size)\n",
        "agent_location = np.random.randint(grid_size * grid_size)\n",
        "traces = np.zeros(grid_size * grid_size)\n",
        "\n",
        "# Function to update the agent's location based on action\n",
        "def update_state(agent_location, action):\n",
        "    if action == \"up\":\n",
        "        new_location = agent_location - 1\n",
        "    elif action == \"down\":\n",
        "        new_location = agent_location + 1\n",
        "    elif action == \"left\":\n",
        "        new_location = agent_location - grid_size\n",
        "    elif action == \"right\":\n",
        "        new_location = agent_location + grid_size\n",
        "    else:\n",
        "        new_location = agent_location\n",
        "\n",
        "    # Ensure the new location is within the grid boundaries\n",
        "    new_location = max(0, min(new_location, grid_size * grid_size - 1))\n",
        "    return new_location\n",
        "\n",
        "# Simulation loop\n",
        "for timestep in range(3):\n",
        "    # Observe the environment\n",
        "    observation = \"food\" if food_location == agent_location else \"no_food\"\n",
        "    if traces[agent_location] > 0:\n",
        "        observation = \"trace\"\n",
        "\n",
        "    # Infer the agent's and food's locations\n",
        "    qs_agent = agent.infer_states([observation], None, None, None)\n",
        "    qs_food = agent.infer_states([observation], None, None, None)\n",
        "\n",
        "    # Update the environment based on agent's beliefs\n",
        "    if np.argmax(qs_food[0]) == food_location:\n",
        "        # Agent found food, leave a trace\n",
        "        traces[agent_location] = 1.0\n",
        "        model.A[\"observation\"][\"food\", agent_location, food_location, traces] = 1.0\n",
        "        model.A[\"observation\"][\"no_food\", agent_location, food_location, traces] = 0.0\n",
        "\n",
        "    # Sample an action based on the inferred state and a policy favoring unexplored areas\n",
        "    q_pi, _ = agent.infer_policies(qs_agent)\n",
        "    q_pi = q_pi * (1 - traces)  # Bias towards unexplored areas\n",
        "    action = agent.sample_action(q_pi)\n",
        "\n",
        "    # Update the agent's location\n",
        "    agent_location = update_state(agent_location, action)\n",
        "\n",
        "    # Print the agent's location and observation\n",
        "    print(f\"Timestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Observation: {observation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "5S1m_Kaakim7",
        "outputId": "92d659ad-717a-424c-a31e-bfa92d8487d7"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for /=: 'Distribution' and 'Distribution'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-81be3c1915cc>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"food_location\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_locations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prefer food locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"food_location\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Don't prefer \"no food\" observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"food_location\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"food_location\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trace_location\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_locations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_locations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Uniform preference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /=: 'Distribution' and 'Distribution'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 3\n",
        "num_locations = grid_size * grid_size\n",
        "\n",
        "# Possible actions\n",
        "actions = [\"up\", \"down\", \"left\", \"right\"]\n",
        "\n",
        "def get_visible_locations(agent_location, grid_size, radius=1):\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    visible = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            x, y = agent_x + dx, agent_y + dy\n",
        "            if 0 <= x < grid_size and 0 <= y < grid_size:\n",
        "                visible.append(x * grid_size + y)\n",
        "    return visible\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    return x * grid_size + y\n",
        "\n",
        "# Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"agent_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"agent_location_state\"],\n",
        "        },\n",
        "        \"food_location\": {\n",
        "            \"elements\": range(num_locations + 1),  # +1 for \"no food\" observation\n",
        "            \"depends_on\": [\"agent_location_state\", \"food_location_state\"],\n",
        "        },\n",
        "        \"trace_location\": {\n",
        "            \"elements\": range(num_locations + 1),  # +1 for \"no trace\" observation\n",
        "            \"depends_on\": [\"agent_location_state\", \"traces_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"action\": {\"elements\": actions},\n",
        "        \"place_trace\": {\"elements\": [\"yes\", \"no\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"agent_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"agent_location_state\"],\n",
        "            \"controlled_by\": [\"action\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"action\"],  # Food doesn't move, but including for completeness\n",
        "        },\n",
        "        \"traces_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"traces_state\", \"agent_location_state\"],\n",
        "            \"controlled_by\": [\"place_trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "# Populate A matrices\n",
        "# Agent location observation (identity mapping)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"agent_location\"][i, i] = 1.0\n",
        "\n",
        "# Food location observation\n",
        "for agent_loc in range(num_locations):\n",
        "    visible_locations = get_visible_locations(agent_loc, grid_size)\n",
        "    for food_loc in range(num_locations):\n",
        "        if food_loc in visible_locations:\n",
        "            model.A[\"food_location\"][food_loc, agent_loc, food_loc] = 1.0\n",
        "        else:\n",
        "            model.A[\"food_location\"][num_locations, agent_loc, food_loc] = 1.0  # No food observed\n",
        "\n",
        "# Trace observation\n",
        "for agent_loc in range(num_locations):\n",
        "    for trace_loc in range(num_locations):\n",
        "        if trace_loc == agent_loc:\n",
        "            model.A[\"trace_location\"][trace_loc, agent_loc, trace_loc] = 1.0\n",
        "        else:\n",
        "            model.A[\"trace_location\"][num_locations, agent_loc, trace_loc] = 1.0  # No trace observed\n",
        "\n",
        "# Populate B matrices\n",
        "# Agent movement\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(actions):\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "        model.B[\"agent_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# Traces update\n",
        "for current_trace in range(num_locations):\n",
        "    for agent_loc in range(num_locations):\n",
        "        model.B[\"traces_state\"][current_trace, current_trace, agent_loc] = 0.9  # Trace remains with high probability\n",
        "        model.B[\"traces_state\"][agent_loc, current_trace, agent_loc] = 0.1  # Small probability of new trace\n",
        "\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"agent_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "model.C[\"food_location\"] = np.ones(num_locations + 1)  # Prefer food locations\n",
        "model.C[\"food_location\"][-1] = 0  # Don't prefer \"no food\" observation\n",
        "model.C[\"food_location\"] /= np.sum(model.C[\"food_location\"])  # Normalize\n",
        "model.C[\"trace_location\"] = np.ones(num_locations + 1) / (num_locations + 1)  # Uniform preference\n",
        "\n",
        "model.D[\"agent_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"traces_state\"] = np.zeros(num_locations)  # No traces initially\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "traces = np.zeros(num_locations)\n",
        "\n",
        "def run_timestep(agent, agent_location, food_location, traces, previous_action):\n",
        "    # Determine visible locations\n",
        "    visible_locations = get_visible_locations(agent_location, grid_size)\n",
        "\n",
        "    # Create observations\n",
        "    agent_obs = np.zeros(num_locations)\n",
        "    agent_obs[agent_location] = 1\n",
        "\n",
        "    food_obs = np.zeros(num_locations + 1)\n",
        "    if food_location in visible_locations:\n",
        "        food_obs[food_location] = 1\n",
        "    else:\n",
        "        food_obs[-1] = 1  # No food observed\n",
        "\n",
        "    trace_obs = np.zeros(num_locations + 1)\n",
        "    for loc in visible_locations:\n",
        "        if traces[loc] > 0:\n",
        "            trace_obs[loc] = 1\n",
        "    if np.sum(trace_obs) == 0:\n",
        "        trace_obs[-1] = 1  # No trace observed\n",
        "\n",
        "    observations = [jnp.array(agent_obs), jnp.array(food_obs), jnp.array(trace_obs)]\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    qs_init = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "    # Infer the empirical prior\n",
        "    prior, _ = agent.infer_empirical_prior(jnp.array([[actions.index(previous_action)]]), qs_init)\n",
        "\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "\n",
        "    # Infer policies and sample action\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    action_index = agent.sample_action(q_pi)[0][0]\n",
        "    action = actions[action_index]\n",
        "\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, action, grid_size)\n",
        "\n",
        "    # Update traces\n",
        "    if new_agent_location == food_location:\n",
        "        traces[agent_location] = 1.0\n",
        "\n",
        "    return qs, action, new_agent_location, traces\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 10\n",
        "previous_action = \"up\"  # Initial action\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, action, agent_location, traces = run_timestep(agent, agent_location, food_location, traces, previous_action)\n",
        "\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Action taken: {action}\")\n",
        "    print(f\"Traces: {traces}\")\n",
        "\n",
        "    previous_action = action\n",
        "\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        break\n",
        "\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-AsW5S7nPpd",
        "outputId": "6b178748-231f-40ec-b68c-fe383ba146fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///C:/Users/Mahault/OneDrive/Desktop/projects/archeology/myenv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: file:///C:/Users/Mahault/OneDrive/Desktop/projects/archeology/myenv does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n",
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Mahault\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!cd ..\n",
        "!cd archeology/pymdp\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "Sab4fvZHvwFs",
        "outputId": "7b904e5e-d893-4794-8874-cd826a0e4665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Timestep 1:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Timestep 2:\n",
            "Agent location: 3\n",
            "Food location: 2\n",
            "Movement action: up\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 3:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 4:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 5:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 6:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 7:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 8:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 9:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 10:\n",
            "Agent location: 6\n",
            "Food location: 2\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "Maximum timesteps reached. Food not found.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 3\n",
        "num_locations = grid_size * grid_size\n",
        "\n",
        "# Possible actions\n",
        "movement_actions = [\"up\", \"down\", \"left\", \"right\"]\n",
        "trace_actions = [\"leave_trace\", \"no_trace\"]\n",
        "\n",
        "\n",
        "def get_visible_locations(agent_location, grid_size, radius=1):\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    visible = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            x, y = agent_x + dx, agent_y + dy\n",
        "            if 0 <= x < grid_size and 0 <= y < grid_size:\n",
        "                visible.append(x * grid_size + y)\n",
        "    return visible\n",
        "\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    return x * grid_size + y\n",
        "\n",
        "\n",
        "# Updated Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"self_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "        },\n",
        "        \"food_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "        },\n",
        "        \"trace_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"trace_location_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"movement\": {\"elements\": movement_actions},\n",
        "        \"trace\": {\"elements\": trace_actions},\n",
        "        \"food_location_action\": {\"elements\": [\"nil\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"self_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "            \"controlled_by\": [\"movement\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"food_location_action\"],\n",
        "        },\n",
        "        \"trace_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"trace_location_state\", \"self_location_state\"],\n",
        "            \"controlled_by\": [\"trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "# Populate A matrices\n",
        "# Self location observation (identity mapping)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"self_location\"][i, i] = 1.0\n",
        "\n",
        "# Food present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        if self_loc == food_loc:\n",
        "            model.A[\"food_present\"][0, self_loc, food_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"food_present\"][1, self_loc, food_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Trace present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for trace_loc in range(num_locations):\n",
        "        if self_loc == trace_loc:\n",
        "            model.A[\"trace_present\"][0, self_loc, trace_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"trace_present\"][1, self_loc, trace_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Populate B matrices\n",
        "# Self movement\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(movement_actions):\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "        model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# Traces update\n",
        "for current_trace in range(num_locations):\n",
        "    for self_loc in range(num_locations):\n",
        "        model.B[\"trace_location_state\"][current_trace, current_trace, self_loc, 0] = 1.0  # Existing trace remains\n",
        "        model.B[\"trace_location_state\"][self_loc, current_trace, self_loc, 1] = 1.0  # New trace is created\n",
        "\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"self_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "model.C[\"food_present\"] = np.array([1.0, 0.0])  # Prefer food present\n",
        "model.C[\"trace_present\"] = np.array([0.5, 0.5])  # Neutral about traces\n",
        "\n",
        "model.D[\"self_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"trace_location_state\"] = np.zeros(num_locations)  # No traces initially\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "traces = np.zeros(num_locations)\n",
        "\n",
        "\n",
        "def run_timestep(agent, agent_location, food_location, traces, previous_movement, previous_trace):\n",
        "    # Generate observations\n",
        "    self_loc_obs = np.zeros(num_locations)\n",
        "    self_loc_obs[agent_location] = 1\n",
        "\n",
        "    food_present_obs = np.zeros(2)\n",
        "    food_present_obs[0 if agent_location == food_location else 1] = 1\n",
        "\n",
        "    trace_present_obs = np.zeros(2)\n",
        "    trace_present_obs[0 if traces[agent_location] > 0 else 1] = 1\n",
        "\n",
        "    observations = [jnp.array(self_loc_obs), jnp.array(food_present_obs), jnp.array(trace_present_obs)]\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    qs_init = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "    # Infer the empirical prior\n",
        "    previous_actions = jnp.array([[movement_actions.index(previous_movement), trace_actions.index(previous_trace), 0]])\n",
        "    prior, _ = agent.infer_empirical_prior(previous_actions, qs_init)\n",
        "\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "\n",
        "    # Infer policies and sample actions\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    movement_action_index, trace_action_index, _ = agent.sample_action(q_pi)[0]\n",
        "    movement_action = movement_actions[movement_action_index]\n",
        "    trace_action = trace_actions[trace_action_index]\n",
        "\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, movement_action, grid_size)\n",
        "\n",
        "    # Update traces\n",
        "    if trace_action == \"leave_trace\":\n",
        "        traces[agent_location] = 1.0\n",
        "\n",
        "    return qs, movement_action, trace_action, new_agent_location, traces\n",
        "\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 10\n",
        "previous_movement = \"up\"\n",
        "previous_trace = \"no_trace\"\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, movement_action, trace_action, agent_location, traces = run_timestep(\n",
        "        agent, agent_location, food_location, traces, previous_movement, previous_trace\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Movement action: {movement_action}\")\n",
        "    print(f\"Trace action: {trace_action}\")\n",
        "    print(f\"Traces: {traces}\")\n",
        "\n",
        "    previous_movement = movement_action\n",
        "    previous_trace = trace_action\n",
        "\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        break\n",
        "\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WpOttmZN32Ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent location: 0\n",
            "Food location: 6\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Timestep 1:\n",
            "Agent location: 3\n",
            "Food location: 6\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Timestep 2:\n",
            "Agent location: 0\n",
            "Food location: 6\n",
            "Movement action: up\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Timestep 3:\n",
            "Agent location: 3\n",
            "Food location: 6\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Timestep 4:\n",
            "Agent location: 6\n",
            "Food location: 6\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "Food found!\n",
            "\n",
            "Timestep 5:\n",
            "Agent location: 6\n",
            "Food location: 6\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "Food found!\n",
            "\n",
            "Timestep 6:\n",
            "Agent location: 3\n",
            "Food location: 6\n",
            "Movement action: up\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 7:\n",
            "Agent location: 6\n",
            "Food location: 6\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "Food found!\n",
            "\n",
            "Timestep 8:\n",
            "Agent location: 3\n",
            "Food location: 6\n",
            "Movement action: up\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 9:\n",
            "Agent location: 6\n",
            "Food location: 6\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "Food found!\n",
            "\n",
            "Timestep 10:\n",
            "Agent location: 3\n",
            "Food location: 6\n",
            "Movement action: up\n",
            "Trace action: leave_trace\n",
            "Traces: [1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "Maximum timesteps reached. Food not found.\n",
            "GIF saved as 'agent_movement.gif'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mahault\\AppData\\Local\\Temp\\ipykernel_10616\\1304076185.py:261: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        }
      ],
      "source": [
        "### Adding a logic to save a gif\n",
        "\n",
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 3\n",
        "num_locations = grid_size * grid_size\n",
        "\n",
        "# Possible actions\n",
        "movement_actions = [\"up\", \"down\", \"left\", \"right\"]\n",
        "trace_actions = [\"leave_trace\", \"no_trace\"]\n",
        "\n",
        "# Directory to save frames\n",
        "frame_dir = \"frames\"\n",
        "if not os.path.exists(frame_dir):\n",
        "    os.makedirs(frame_dir)\n",
        "\n",
        "\n",
        "def get_visible_locations(agent_location, grid_size, radius=1):\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    visible = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            x, y = agent_x + dx, agent_y + dy\n",
        "            if 0 <= x < grid_size and 0 <= y < grid_size:\n",
        "                visible.append(x * grid_size + y)\n",
        "    return visible\n",
        "\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    return x * grid_size + y\n",
        "\n",
        "\n",
        "def plot_grid(agent_location, food_location, traces, grid_size, timestep):\n",
        "    \"\"\"Plot the grid world, showing the agent, food, and traces.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    # Draw grid\n",
        "    for i in range(grid_size + 1):\n",
        "        ax.plot([i, i], [0, grid_size], color=\"black\")\n",
        "        ax.plot([0, grid_size], [i, i], color=\"black\")\n",
        "\n",
        "    # Plot food location\n",
        "    food_x, food_y = divmod(food_location, grid_size)\n",
        "    ax.text(food_y + 0.5, grid_size - food_x - 0.5, 'F', color=\"green\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot traces\n",
        "    for i, trace in enumerate(traces):\n",
        "        if trace > 0:\n",
        "            trace_x, trace_y = divmod(i, grid_size)\n",
        "            ax.text(trace_y + 0.5, grid_size - trace_x - 0.5, 'T', color=\"red\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot agent location\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    ax.text(agent_y + 0.5, grid_size - agent_x - 0.5, 'A', color=\"blue\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Remove ticks and labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    # Save frame\n",
        "    plt.title(f\"Timestep {timestep}\")\n",
        "    plt.savefig(f\"{frame_dir}/frame_{timestep}.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Updated Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"self_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "        },\n",
        "        \"food_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "        },\n",
        "        \"trace_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"trace_location_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"movement\": {\"elements\": movement_actions},\n",
        "        \"trace\": {\"elements\": trace_actions},\n",
        "        \"food_location_action\": {\"elements\": [\"nil\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"self_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "            \"controlled_by\": [\"movement\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"food_location_action\"],\n",
        "        },\n",
        "        \"trace_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"trace_location_state\", \"self_location_state\"],\n",
        "            \"controlled_by\": [\"trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "# Populate A matrices\n",
        "# Self location observation (identity mapping)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"self_location\"][i, i] = 1.0\n",
        "\n",
        "# Food present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        if self_loc == food_loc:\n",
        "            model.A[\"food_present\"][0, self_loc, food_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"food_present\"][1, self_loc, food_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Trace present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for trace_loc in range(num_locations):\n",
        "        if self_loc == trace_loc:\n",
        "            model.A[\"trace_present\"][0, self_loc, trace_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"trace_present\"][1, self_loc, trace_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Populate B matrices\n",
        "# Self movement\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(movement_actions):\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "        model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# Traces update\n",
        "for current_trace in range(num_locations):\n",
        "    for self_loc in range(num_locations):\n",
        "        model.B[\"trace_location_state\"][current_trace, current_trace, self_loc, 0] = 1.0  # Existing trace remains\n",
        "        model.B[\"trace_location_state\"][self_loc, current_trace, self_loc, 1] = 1.0  # New trace is created\n",
        "\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"self_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "model.C[\"food_present\"] = np.array([1.0, 0.0])  # Prefer food present\n",
        "model.C[\"trace_present\"] = np.array([0.5, 0.5])  # Neutral about traces\n",
        "\n",
        "model.D[\"self_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"trace_location_state\"] = np.zeros(num_locations)  # No traces initially\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True, policy_len=5)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "traces = np.zeros(num_locations)\n",
        "\n",
        "print(f\"Agent location: {agent_location}\")\n",
        "print(f\"Food location: {food_location}\")\n",
        "print(f\"Traces: {traces}\")\n",
        "\n",
        "\n",
        "def run_timestep(agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep):\n",
        "    # Generate observations\n",
        "    self_loc_obs = np.zeros(num_locations)\n",
        "    self_loc_obs[agent_location] = 1\n",
        "\n",
        "    food_present_obs = np.zeros(2)\n",
        "    food_present_obs[0 if agent_location == food_location else 1] = 1\n",
        "\n",
        "    trace_present_obs = np.zeros(2)\n",
        "    trace_present_obs[0 if traces[agent_location] > 0 else 1] = 1\n",
        "\n",
        "    observations = [jnp.array(self_loc_obs), jnp.array(food_present_obs), jnp.array(trace_present_obs)]\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    qs_init = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "    # Infer the empirical prior\n",
        "    previous_actions = jnp.array([[movement_actions.index(previous_movement), trace_actions.index(previous_trace), 0]])\n",
        "    prior, _ = agent.infer_empirical_prior(previous_actions, qs_init)\n",
        "\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "\n",
        "    # Infer policies and sample actions\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    movement_action_index, trace_action_index, _ = agent.sample_action(q_pi)[0]\n",
        "    movement_action = movement_actions[movement_action_index]\n",
        "    trace_action = trace_actions[trace_action_index]\n",
        "\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, movement_action, grid_size)\n",
        "\n",
        "    # Update traces\n",
        "    if trace_action == \"leave_trace\":\n",
        "        traces[agent_location] = 1.0\n",
        "\n",
        "    # Plot the grid for this timestep\n",
        "    plot_grid(new_agent_location, food_location, traces, grid_size, timestep)\n",
        "\n",
        "    return qs, movement_action, trace_action, new_agent_location, traces\n",
        "\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 10\n",
        "previous_movement = \"up\"\n",
        "previous_trace = \"no_trace\"\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, movement_action, trace_action, agent_location, traces = run_timestep(\n",
        "        agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Movement action: {movement_action}\")\n",
        "    print(f\"Trace action: {trace_action}\")\n",
        "    print(f\"Traces: {traces}\")\n",
        "\n",
        "    previous_movement = movement_action\n",
        "    previous_trace = trace_action\n",
        "\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        # break\n",
        "\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")\n",
        "\n",
        "# Create GIF\n",
        "with imageio.get_writer(\"agent_movement.gif\", mode=\"I\", duration=0.5) as writer:\n",
        "    for i in range(num_timesteps):\n",
        "        filename = f\"{frame_dir}/frame_{i}.png\"\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "print(\"GIF saved as 'agent_movement.gif'.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 146\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trace_loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_locations):\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Case 1: Both food and trace are present at the same location as the agent\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m self_loc \u001b[38;5;241m==\u001b[39m food_loc \u001b[38;5;129;01mand\u001b[39;00m self_loc \u001b[38;5;241m==\u001b[39m trace_loc:\n\u001b[1;32m--> 146\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfood_present\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfood_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_loc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m prob_food_and_trace  \u001b[38;5;66;03m# \"yes\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m         model\u001b[38;5;241m.\u001b[39mA[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfood_present\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m, self_loc, food_loc, trace_loc] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m prob_food_and_trace  \u001b[38;5;66;03m# \"no\"\u001b[39;00m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# Case 2: Only food is present (no trace)\u001b[39;00m\n",
            "File \u001b[1;32m~\\OneDrive\\Desktop\\projects\\archeology\\pymdp\\pymdp\\jax\\distribution.py:88\u001b[0m, in \u001b[0;36mDistribution.__setitem__\u001b[1;34m(self, indices, value)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indices, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m     87\u001b[0m     indices \u001b[38;5;241m=\u001b[39m (indices,)\n\u001b[1;32m---> 88\u001b[0m index_list \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_index_from_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mtuple\u001b[39m(index_list)] \u001b[38;5;241m=\u001b[39m value\n",
            "File \u001b[1;32m~\\OneDrive\\Desktop\\projects\\archeology\\pymdp\\pymdp\\jax\\distribution.py:89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indices, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m     87\u001b[0m     indices \u001b[38;5;241m=\u001b[39m (indices,)\n\u001b[0;32m     88\u001b[0m index_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_index_from_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(indices)\n\u001b[0;32m     90\u001b[0m ]\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mtuple\u001b[39m(index_list)] \u001b[38;5;241m=\u001b[39m value\n",
            "File \u001b[1;32m~\\OneDrive\\Desktop\\projects\\archeology\\pymdp\\pymdp\\jax\\distribution.py:73\u001b[0m, in \u001b[0;36mDistribution._get_index_from_axis\u001b[1;34m(self, axis, element)\u001b[0m\n\u001b[0;32m     71\u001b[0m     index_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_indices[key]\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     74\u001b[0m     index_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_indices[key]\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index(element, index_map)\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "##### Now changing the trace action to depend on food being observed\n",
        "\n",
        "### Adding a logic to save a gif\n",
        "\n",
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 3\n",
        "num_locations = grid_size * grid_size\n",
        "\n",
        "# Possible actions\n",
        "movement_actions = [\"up\", \"down\", \"left\", \"right\"]\n",
        "trace_actions = [\"leave_trace\", \"no_trace\"]\n",
        "\n",
        "# Directory to save frames\n",
        "frame_dir = \"frames\"\n",
        "if not os.path.exists(frame_dir):\n",
        "    os.makedirs(frame_dir)\n",
        "\n",
        "\n",
        "def get_visible_locations(agent_location, grid_size, radius=1):\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    visible = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            x, y = agent_x + dx, agent_y + dy\n",
        "            if 0 <= x < grid_size and 0 <= y < grid_size:\n",
        "                visible.append(x * grid_size + y)\n",
        "    return visible\n",
        "\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    return x * grid_size + y\n",
        "\n",
        "\n",
        "def plot_grid(agent_location, food_location, traces, grid_size, timestep):\n",
        "    \"\"\"Plot the grid world, showing the agent, food, and traces.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    # Draw grid\n",
        "    for i in range(grid_size + 1):\n",
        "        ax.plot([i, i], [0, grid_size], color=\"black\")\n",
        "        ax.plot([0, grid_size], [i, i], color=\"black\")\n",
        "\n",
        "    # Plot food location\n",
        "    food_x, food_y = divmod(food_location, grid_size)\n",
        "    ax.text(food_y + 0.5, grid_size - food_x - 0.5, 'F', color=\"green\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot traces\n",
        "    for i, trace in enumerate(traces):\n",
        "        if trace > 0:\n",
        "            trace_x, trace_y = divmod(i, grid_size)\n",
        "            ax.text(trace_y + 0.5, grid_size - trace_x - 0.5, 'T', color=\"red\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot agent location\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    ax.text(agent_y + 0.5, grid_size - agent_x - 0.5, 'A', color=\"blue\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Remove ticks and labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    # Save frame\n",
        "    plt.title(f\"Timestep {timestep}\")\n",
        "    plt.savefig(f\"{frame_dir}/frame_{timestep}.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Updated Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"self_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "        },\n",
        "        \"food_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "        },\n",
        "        \"trace_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"trace_location_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"movement\": {\"elements\": movement_actions},\n",
        "        \"trace\": {\"elements\": trace_actions},\n",
        "        \"food_location_action\": {\"elements\": [\"nil\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"self_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "            \"controlled_by\": [\"movement\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"food_location_action\"],\n",
        "        },\n",
        "        \"trace_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"trace_location_state\", \"self_location_state\", \"food_location_state\"],\n",
        "            \"controlled_by\": [\"trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "# Populate A matrices\n",
        "# Self location observation (identity mapping)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"self_location\"][i, i] = 1.0\n",
        "\n",
        "\n",
        "# Food present observation\n",
        "# Set base probabilities for food present (high for food + trace, medium for trace alone, low for neither)\n",
        "prob_food_and_trace = 1.0  # Probability when both food and trace are present\n",
        "prob_only_trace = 0.7      # Slightly higher probability when only trace is present\n",
        "prob_none = 0.0            # Probability when neither food nor trace is present\n",
        "\n",
        "\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        for trace_loc in range(num_locations):\n",
        "            # Case 1: Both food and trace are present at the same location as the agent\n",
        "            if self_loc == food_loc and self_loc == trace_loc:\n",
        "                model.A[\"food_present\"][0, self_loc, food_loc, trace_loc] = prob_food_and_trace  # \"yes\"\n",
        "                model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_food_and_trace  # \"no\"\n",
        "\n",
        "            # Case 2: Only food is present (no trace)\n",
        "            elif self_loc == food_loc and self_loc != trace_loc:\n",
        "                model.A[\"food_present\"][0, self_loc, food_loc, trace_loc] = prob_food_and_trace  # \"yes\"\n",
        "                model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_food_and_trace  # \"no\"\n",
        "\n",
        "            # Case 3: Only trace is present (no food)\n",
        "            elif self_loc != food_loc and self_loc == trace_loc:\n",
        "                model.A[\"food_present\"][0, self_loc, food_loc, trace_loc] = prob_only_trace  # \"yes\" with lower probability\n",
        "                model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_only_trace  # \"no\"\n",
        "\n",
        "            # Case 4: Neither food nor trace is present\n",
        "            else:\n",
        "                model.A[\"food_present\"][0, self_loc, food_loc, trace_loc] = prob_none  # \"yes\"\n",
        "                model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_none  # \"no\"\n",
        "\n",
        "\n",
        "# Trace present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for trace_loc in range(num_locations):\n",
        "        if self_loc == trace_loc:\n",
        "            model.A[\"trace_present\"][0, self_loc, trace_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"trace_present\"][1, self_loc, trace_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Populate B matrices\n",
        "# Self movement\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(movement_actions):\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "        model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# Traces update\n",
        "for current_trace in range(num_locations):\n",
        "    for self_loc in range(num_locations):\n",
        "        model.B[\"trace_location_state\"][current_trace, current_trace, self_loc, 0] = 1.0  # Existing trace remains\n",
        "        model.B[\"trace_location_state\"][self_loc, current_trace, self_loc, 1] = 1.0  # New trace is created\n",
        "\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"self_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "model.C[\"food_present\"] = np.array([1.0, 0.0])  # Prefer food present\n",
        "model.C[\"trace_present\"] = np.array([0.5, 0.5])  # Neutral about traces\n",
        "\n",
        "model.D[\"self_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"trace_location_state\"] = np.zeros(num_locations)  # No traces initially\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "traces = np.zeros(num_locations)\n",
        "\n",
        "print(f\"Agent location: {agent_location}\")\n",
        "print(f\"Food location: {food_location}\")\n",
        "print(f\"Traces: {traces}\")\n",
        "\n",
        "\n",
        "def run_timestep(agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep):\n",
        "    # Generate observations\n",
        "    self_loc_obs = np.zeros(num_locations)\n",
        "    self_loc_obs[agent_location] = 1\n",
        "\n",
        "    food_present_obs = np.zeros(2)\n",
        "    food_present_obs[0 if agent_location == food_location else 1] = 1\n",
        "\n",
        "    trace_present_obs = np.zeros(2)\n",
        "    trace_present_obs[0 if traces[agent_location] > 0 else 1] = 1\n",
        "\n",
        "    observations = [jnp.array(self_loc_obs), jnp.array(food_present_obs), jnp.array(trace_present_obs)]\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    qs_init = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "    # Infer the empirical prior\n",
        "    previous_actions = jnp.array([[movement_actions.index(previous_movement), trace_actions.index(previous_trace), 0]])\n",
        "    prior, _ = agent.infer_empirical_prior(previous_actions, qs_init)\n",
        "\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "\n",
        "    # Infer policies and sample actions\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    movement_action_index, trace_action_index, _ = agent.sample_action(q_pi)[0]\n",
        "    movement_action = movement_actions[movement_action_index]\n",
        "    trace_action = trace_actions[trace_action_index]\n",
        "\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, movement_action, grid_size)\n",
        "\n",
        "    # Update traces\n",
        "    if trace_action == \"leave_trace\":\n",
        "        traces[agent_location] = 1.0\n",
        "\n",
        "    # Plot the grid for this timestep\n",
        "    plot_grid(new_agent_location, food_location, traces, grid_size, timestep)\n",
        "\n",
        "    return qs, movement_action, trace_action, new_agent_location, traces\n",
        "\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 10\n",
        "previous_movement = \"up\"\n",
        "previous_trace = \"no_trace\"\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, movement_action, trace_action, agent_location, traces = run_timestep(\n",
        "        agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Movement action: {movement_action}\")\n",
        "    print(f\"Trace action: {trace_action}\")\n",
        "    print(f\"Traces: {traces}\")\n",
        "\n",
        "    previous_movement = movement_action\n",
        "    previous_trace = trace_action\n",
        "\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        # break\n",
        "\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")\n",
        "\n",
        "# Create GIF\n",
        "with imageio.get_writer(\"agent_movement.gif\", mode=\"I\", duration=0.5) as writer:\n",
        "    for i in range(num_timesteps):\n",
        "        filename = f\"{frame_dir}/frame_{i}.png\"\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "print(\"GIF saved as 'agent_movement.gif'.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent location: 20\n",
            "Food location: 16\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 1:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 2:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 3:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 4:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 5:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 6:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 7:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 8:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 9:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "\n",
            "Timestep 10:\n",
            "Agent location: 20\n",
            "Food location: 16\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0.]\n",
            "Maximum timesteps reached. Food not found.\n",
            "GIF saved as 'agent_movement.gif'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mahault\\AppData\\Local\\Temp\\ipykernel_10616\\2231428357.py:266: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        }
      ],
      "source": [
        "#### Adding an action to stay and preference for food present is really high\n",
        "\n",
        "### Adding a logic to save a gif\n",
        "\n",
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 5\n",
        "num_locations = grid_size * grid_size\n",
        "\n",
        "# Possible actions\n",
        "movement_actions = [\"up\", \"down\", \"left\", \"right\", \"stay\"]\n",
        "trace_actions = [\"leave_trace\", \"no_trace\"]\n",
        "\n",
        "# Directory to save frames\n",
        "frame_dir = \"frames\"\n",
        "if not os.path.exists(frame_dir):\n",
        "    os.makedirs(frame_dir)\n",
        "\n",
        "\n",
        "def get_visible_locations(agent_location, grid_size, radius=1):\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    visible = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            x, y = agent_x + dx, agent_y + dy\n",
        "            if 0 <= x < grid_size and 0 <= y < grid_size:\n",
        "                visible.append(x * grid_size + y)\n",
        "    return visible\n",
        "\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    elif action == \"stay\":\n",
        "        pass  # No change in location\n",
        "    return x * grid_size + y\n",
        "\n",
        "\n",
        "def plot_grid(agent_location, food_location, traces, grid_size, timestep):\n",
        "    \"\"\"Plot the grid world, showing the agent, food, and traces.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    # Draw grid\n",
        "    for i in range(grid_size + 1):\n",
        "        ax.plot([i, i], [0, grid_size], color=\"black\")\n",
        "        ax.plot([0, grid_size], [i, i], color=\"black\")\n",
        "\n",
        "    # Plot food location\n",
        "    food_x, food_y = divmod(food_location, grid_size)\n",
        "    ax.text(food_y + 0.5, grid_size - food_x - 0.5, 'F', color=\"green\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot traces\n",
        "    for i, trace in enumerate(traces):\n",
        "        if trace > 0:\n",
        "            trace_x, trace_y = divmod(i, grid_size)\n",
        "            ax.text(trace_y + 0.5, grid_size - trace_x - 0.5, 'T', color=\"red\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot agent location\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    ax.text(agent_y + 0.5, grid_size - agent_x - 0.5, 'A', color=\"blue\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Remove ticks and labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    # Save frame\n",
        "    plt.title(f\"Timestep {timestep}\")\n",
        "    plt.savefig(f\"{frame_dir}/frame_{timestep}.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Updated Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"self_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "        },\n",
        "        \"food_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "        },\n",
        "        \"trace_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"trace_location_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"movement\": {\"elements\": movement_actions},\n",
        "        \"trace\": {\"elements\": trace_actions},\n",
        "        \"food_location_action\": {\"elements\": [\"nil\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"self_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "            \"controlled_by\": [\"movement\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"food_location_action\"],\n",
        "        },\n",
        "        \"trace_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"trace_location_state\", \"self_location_state\"],\n",
        "            \"controlled_by\": [\"trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "# Populate A matrices\n",
        "# Self location observation (identity mapping)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"self_location\"][i, i] = 1.0\n",
        "\n",
        "# Food present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        if self_loc == food_loc:\n",
        "            model.A[\"food_present\"][0, self_loc, food_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"food_present\"][1, self_loc, food_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Trace present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for trace_loc in range(num_locations):\n",
        "        if self_loc == trace_loc:\n",
        "            model.A[\"trace_present\"][0, self_loc, trace_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"trace_present\"][1, self_loc, trace_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Populate B matrices\n",
        "# Self movement\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(movement_actions):\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "        model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# Traces update\n",
        "for current_trace in range(num_locations):\n",
        "    for self_loc in range(num_locations):\n",
        "        model.B[\"trace_location_state\"][current_trace, current_trace, self_loc, 0] = 1.0  # Existing trace remains\n",
        "        model.B[\"trace_location_state\"][self_loc, current_trace, self_loc, 1] = 1.0  # New trace is created\n",
        "\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"self_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "# model.C[\"food_present\"] = np.array([1.0, 0.0])  # Prefer food present\n",
        "model.C[\"food_present\"] = np.array([10.0, 0.0])  # Prefer food present\n",
        "model.C[\"trace_present\"] = np.array([0.5, 0.5])  # Neutral about traces\n",
        "\n",
        "model.D[\"self_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"trace_location_state\"] = np.zeros(num_locations)  # No traces initially\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True, policy_len=3)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "traces = np.zeros(num_locations)\n",
        "\n",
        "print(f\"Agent location: {agent_location}\")\n",
        "print(f\"Food location: {food_location}\")\n",
        "print(f\"Traces: {traces}\")\n",
        "\n",
        "\n",
        "def run_timestep(agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep):\n",
        "    # Generate observations\n",
        "    self_loc_obs = np.zeros(num_locations)\n",
        "    self_loc_obs[agent_location] = 1\n",
        "\n",
        "    food_present_obs = np.zeros(2)\n",
        "    food_present_obs[0 if agent_location == food_location else 1] = 1\n",
        "\n",
        "    trace_present_obs = np.zeros(2)\n",
        "    trace_present_obs[0 if traces[agent_location] > 0 else 1] = 1\n",
        "\n",
        "    observations = [jnp.array(self_loc_obs), jnp.array(food_present_obs), jnp.array(trace_present_obs)]\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    qs_init = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "    # Infer the empirical prior\n",
        "    previous_actions = jnp.array([[movement_actions.index(previous_movement), trace_actions.index(previous_trace), 0]])\n",
        "    prior, _ = agent.infer_empirical_prior(previous_actions, qs_init)\n",
        "\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "\n",
        "    # Infer policies and sample actions\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    movement_action_index, trace_action_index, _ = agent.sample_action(q_pi)[0]\n",
        "    movement_action = movement_actions[movement_action_index]\n",
        "    trace_action = trace_actions[trace_action_index]\n",
        "\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, movement_action, grid_size)\n",
        "\n",
        "    # Update traces\n",
        "    if trace_action == \"leave_trace\":\n",
        "        traces[agent_location] = 1.0\n",
        "\n",
        "    # Plot the grid for this timestep\n",
        "    plot_grid(new_agent_location, food_location, traces, grid_size, timestep)\n",
        "\n",
        "    return qs, movement_action, trace_action, new_agent_location, traces\n",
        "\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 10\n",
        "previous_movement = \"up\"\n",
        "previous_trace = \"no_trace\"\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, movement_action, trace_action, agent_location, traces = run_timestep(\n",
        "        agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Movement action: {movement_action}\")\n",
        "    print(f\"Trace action: {trace_action}\")\n",
        "    print(f\"Traces: {traces}\")\n",
        "\n",
        "    previous_movement = movement_action\n",
        "    previous_trace = trace_action\n",
        "\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        # break\n",
        "\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")\n",
        "\n",
        "# Create GIF\n",
        "with imageio.get_writer(\"agent_movement.gif\", mode=\"I\", duration=0.5) as writer:\n",
        "    for i in range(num_timesteps):\n",
        "        filename = f\"{frame_dir}/frame_{i}.png\"\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "print(\"GIF saved as 'agent_movement.gif'.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent location: 3\n",
            "Food location: 7\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Timestep 1:\n",
            "Agent location: 6\n",
            "Food location: 7\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Timestep 2:\n",
            "Agent location: 6\n",
            "Food location: 7\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Timestep 3:\n",
            "Agent location: 7\n",
            "Food location: 7\n",
            "Movement action: right\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            "Food found!\n",
            "\n",
            "Timestep 4:\n",
            "Agent location: 7\n",
            "Food location: 7\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "Food found!\n",
            "\n",
            "Timestep 5:\n",
            "Agent location: 6\n",
            "Food location: 7\n",
            "Movement action: left\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "\n",
            "Timestep 6:\n",
            "Agent location: 7\n",
            "Food location: 7\n",
            "Movement action: right\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "Food found!\n",
            "\n",
            "Timestep 7:\n",
            "Agent location: 6\n",
            "Food location: 7\n",
            "Movement action: left\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "\n",
            "Timestep 8:\n",
            "Agent location: 7\n",
            "Food location: 7\n",
            "Movement action: right\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "Food found!\n",
            "\n",
            "Timestep 9:\n",
            "Agent location: 6\n",
            "Food location: 7\n",
            "Movement action: left\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "\n",
            "Timestep 10:\n",
            "Agent location: 7\n",
            "Food location: 7\n",
            "Movement action: right\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "Food found!\n",
            "Maximum timesteps reached. Food not found.\n",
            "GIF saved as 'agent_movement.gif'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mahault\\AppData\\Local\\Temp\\ipykernel_10616\\40450965.py:280: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        }
      ],
      "source": [
        "#### Now plotting the agent's beliefs about where the food is\n",
        "\n",
        "#### Adding an action to stay and preference for food present is really high\n",
        "\n",
        "### Adding a logic to save a gif\n",
        "\n",
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 3\n",
        "num_locations = grid_size * grid_size\n",
        "\n",
        "# Possible actions\n",
        "movement_actions = [\"up\", \"down\", \"left\", \"right\", \"stay\"]\n",
        "trace_actions = [\"leave_trace\", \"no_trace\"]\n",
        "\n",
        "# Directory to save frames\n",
        "frame_dir = \"frames\"\n",
        "if not os.path.exists(frame_dir):\n",
        "    os.makedirs(frame_dir)\n",
        "\n",
        "\n",
        "def get_visible_locations(agent_location, grid_size, radius=1):\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    visible = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            x, y = agent_x + dx, agent_y + dy\n",
        "            if 0 <= x < grid_size and 0 <= y < grid_size:\n",
        "                visible.append(x * grid_size + y)\n",
        "    return visible\n",
        "\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    elif action == \"stay\":\n",
        "        pass  # No change in location\n",
        "    return x * grid_size + y\n",
        "\n",
        "\n",
        "def plot_grid(agent_location, food_location, traces, grid_size, timestep, food_beliefs):\n",
        "    \"\"\"Plot the grid world, showing the agent, food, traces, and beliefs about food location.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    # Draw grid\n",
        "    for i in range(grid_size + 1):\n",
        "        ax.plot([i, i], [0, grid_size], color=\"black\")\n",
        "        ax.plot([0, grid_size], [i, i], color=\"black\")\n",
        "\n",
        "    # Plot belief about food location using light colored squares\n",
        "    for i in range(num_locations):\n",
        "        belief_prob = float(food_beliefs[i])  # Convert JAX array element to Python float\n",
        "        if belief_prob > 0:  # Only color if there's a non-zero belief\n",
        "            x, y = divmod(i, grid_size)\n",
        "            ax.add_patch(plt.Rectangle((y, grid_size - 1 - x), 1, 1, color=\"yellow\", alpha=belief_prob))\n",
        "            ax.text(y + 0.5, grid_size - 1 - x + 0.5, f'{belief_prob:.2f}', \n",
        "                    ha=\"center\", va=\"center\", fontsize=8, color=\"black\")\n",
        "\n",
        "    # Plot food location\n",
        "    food_x, food_y = divmod(food_location, grid_size)\n",
        "    ax.text(food_y + 0.5, grid_size - food_x - 0.5, 'F', color=\"green\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot traces\n",
        "    for i, trace in enumerate(traces):\n",
        "        if trace > 0:\n",
        "            trace_x, trace_y = divmod(i, grid_size)\n",
        "            ax.text(trace_y + 0.5, grid_size - trace_x - 0.5, 'T', color=\"red\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot agent location\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    ax.text(agent_y + 0.5, grid_size - agent_x - 0.5, 'A', color=\"blue\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Remove ticks and labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    # Save frame\n",
        "    plt.title(f\"Timestep {timestep}\")\n",
        "    plt.savefig(f\"{frame_dir}/frame_{timestep}.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Updated Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"self_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "        },\n",
        "        \"food_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            # \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "        },\n",
        "        \"trace_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"trace_location_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"movement\": {\"elements\": movement_actions},\n",
        "        \"trace\": {\"elements\": trace_actions},\n",
        "        \"food_location_action\": {\"elements\": [\"nil\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"self_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "            \"controlled_by\": [\"movement\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"food_location_action\"],\n",
        "        },\n",
        "        \"trace_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"trace_location_state\", \"self_location_state\"],\n",
        "            \"controlled_by\": [\"trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "# Populate A matrices\n",
        "# Self location observation (identity mapping)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"self_location\"][i, i] = 1.0\n",
        "\n",
        "# Food present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        if self_loc == food_loc:\n",
        "            model.A[\"food_present\"][0, self_loc, food_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"food_present\"][1, self_loc, food_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Trace present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for trace_loc in range(num_locations):\n",
        "        if self_loc == trace_loc:\n",
        "            model.A[\"trace_present\"][0, self_loc, trace_loc] = 1.0  # \"yes\"\n",
        "        else:\n",
        "            model.A[\"trace_present\"][1, self_loc, trace_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Populate B matrices\n",
        "# Self movement\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(movement_actions):\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "        model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# Traces update\n",
        "for current_trace in range(num_locations):\n",
        "    for self_loc in range(num_locations):\n",
        "        model.B[\"trace_location_state\"][current_trace, current_trace, self_loc, 0] = 1.0  # Existing trace remains\n",
        "        model.B[\"trace_location_state\"][self_loc, current_trace, self_loc, 1] = 1.0  # New trace is created\n",
        "\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"self_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "# model.C[\"food_present\"] = np.array([1.0, 0.0])  # Prefer food present\n",
        "model.C[\"food_present\"] = np.array([10.0, -10.0])  # Prefer food present\n",
        "model.C[\"trace_present\"] = np.array([0.5, 0.5])  # Neutral about traces\n",
        "\n",
        "model.D[\"self_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"trace_location_state\"] = np.zeros(num_locations)  # No traces initially\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True, policy_len=5)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "traces = np.zeros(num_locations)\n",
        "\n",
        "print(f\"Agent location: {agent_location}\")\n",
        "print(f\"Food location: {food_location}\")\n",
        "print(f\"Traces: {traces}\")\n",
        "\n",
        "\n",
        "def run_timestep(agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep):\n",
        "    # Generate observations\n",
        "    self_loc_obs = np.zeros(num_locations)\n",
        "    self_loc_obs[agent_location] = 1\n",
        "\n",
        "    food_present_obs = np.zeros(2)\n",
        "    food_present_obs[0 if agent_location == food_location else 1] = 1\n",
        "\n",
        "    trace_present_obs = np.zeros(2)\n",
        "    trace_present_obs[0 if traces[agent_location] > 0 else 1] = 1\n",
        "\n",
        "    observations = [jnp.array(self_loc_obs), jnp.array(food_present_obs), jnp.array(trace_present_obs)]\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    qs_init = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "    # Infer the empirical prior\n",
        "    previous_actions = jnp.array([[movement_actions.index(previous_movement), trace_actions.index(previous_trace), 0]])\n",
        "    prior, _ = agent.infer_empirical_prior(previous_actions, qs_init)\n",
        "\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "\n",
        "    # Extract food location beliefs from qs (qs[1] corresponds to food_location_state)\n",
        "    food_beliefs = jnp.squeeze(qs[1][0])\n",
        "\n",
        "    # Infer policies and sample actions\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    movement_action_index, trace_action_index, _ = agent.sample_action(q_pi)[0]\n",
        "    movement_action = movement_actions[movement_action_index]\n",
        "    trace_action = trace_actions[trace_action_index]\n",
        "\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, movement_action, grid_size)\n",
        "\n",
        "    # Update traces\n",
        "    if trace_action == \"leave_trace\":\n",
        "        traces[agent_location] = 1.0\n",
        "\n",
        "    # Plot the grid for this timestep with beliefs\n",
        "    plot_grid(new_agent_location, food_location, traces, grid_size, timestep, food_beliefs)\n",
        "\n",
        "    return qs, movement_action, trace_action, new_agent_location, traces\n",
        "\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 10\n",
        "previous_movement = \"up\"\n",
        "previous_trace = \"no_trace\"\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, movement_action, trace_action, agent_location, traces = run_timestep(\n",
        "        agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Movement action: {movement_action}\")\n",
        "    print(f\"Trace action: {trace_action}\")\n",
        "    print(f\"Traces: {traces}\")\n",
        "\n",
        "    previous_movement = movement_action\n",
        "    previous_trace = trace_action\n",
        "\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        # break\n",
        "\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")\n",
        "\n",
        "# Create GIF\n",
        "with imageio.get_writer(\"agent_movement.gif\", mode=\"I\", duration=0.5) as writer:\n",
        "    for i in range(num_timesteps):\n",
        "        filename = f\"{frame_dir}/frame_{i}.png\"\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "print(\"GIF saved as 'agent_movement.gif'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent location: 10\n",
            "Food location: 0\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [3.361980e-33 6.666667e-02 6.666667e-02 6.666667e-02 6.666667e-02\n",
            " 6.666667e-02 6.666667e-02 6.666667e-02 6.666667e-02 6.666667e-02\n",
            " 6.666667e-02 6.666667e-02 6.666667e-02 6.666667e-02 6.666667e-02\n",
            " 6.666667e-02]\n",
            "\n",
            "Timestep 1:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.4785270e-23 9.1101430e-02 9.1101430e-02 9.1101430e-02 9.0707973e-02\n",
            " 9.0707973e-02 9.0707973e-02 9.0707973e-02 9.0707973e-02 9.0707973e-02\n",
            " 9.0707973e-02 9.0707973e-02 2.5797513e-04 2.5797487e-04 2.5797487e-04\n",
            " 2.5797487e-04]\n",
            "\n",
            "Timestep 2:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.0490625e-17 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02]\n",
            "\n",
            "Timestep 3:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.0490625e-17 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02]\n",
            "\n",
            "Timestep 4:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.0490625e-17 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02]\n",
            "\n",
            "Timestep 5:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.0490625e-17 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02]\n",
            "\n",
            "Timestep 6:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.0490625e-17 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02]\n",
            "\n",
            "Timestep 7:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.0490625e-17 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02]\n",
            "\n",
            "Timestep 8:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.0490625e-17 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02]\n",
            "\n",
            "Timestep 9:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Length of B matrices: 3\n",
            "Shape of previous_actions: (1, 3)\n",
            "food beliefs [7.0490625e-17 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02 6.6666670e-02\n",
            " 6.6666670e-02]\n",
            "\n",
            "Timestep 10:\n",
            "Agent location: 14\n",
            "Food location: 0\n",
            "Movement action: down\n",
            "Trace action: leave_trace\n",
            "Traces: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Maximum timesteps reached. Food not found.\n",
            "GIF saved as 'agent_movement.gif'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mahault\\AppData\\Local\\Temp\\ipykernel_10616\\1096458257.py:388: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        }
      ],
      "source": [
        "### Now trying with the trace dependency again\n",
        "\n",
        "\n",
        "#### Now plotting the agent's beliefs about where the food is\n",
        "\n",
        "#### Adding an action to stay and preference for food present is really high\n",
        "\n",
        "### Adding a logic to save a gif\n",
        "\n",
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 4\n",
        "num_locations = grid_size * grid_size\n",
        "\n",
        "# Possible actions\n",
        "movement_actions = [\"up\", \"down\", \"left\", \"right\", \"stay\"]\n",
        "trace_actions = [\"leave_trace\", \"no_trace\"]\n",
        "\n",
        "# Directory to save frames\n",
        "frame_dir = \"frames\"\n",
        "if not os.path.exists(frame_dir):\n",
        "    os.makedirs(frame_dir)\n",
        "\n",
        "\n",
        "def get_visible_locations(agent_location, grid_size, radius=1):\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    visible = []\n",
        "    for dx in range(-radius, radius + 1):\n",
        "        for dy in range(-radius, radius + 1):\n",
        "            x, y = agent_x + dx, agent_y + dy\n",
        "            if 0 <= x < grid_size and 0 <= y < grid_size:\n",
        "                visible.append(x * grid_size + y)\n",
        "    return visible\n",
        "\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    elif action == \"stay\":\n",
        "        pass  # No change in location\n",
        "    return x * grid_size + y\n",
        "\n",
        "\n",
        "def plot_grid(agent_location, food_location, traces, grid_size, timestep, food_beliefs):\n",
        "    \"\"\"Plot the grid world, showing the agent, food, traces, and beliefs about food location.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    # Draw grid\n",
        "    for i in range(grid_size + 1):\n",
        "        ax.plot([i, i], [0, grid_size], color=\"black\")\n",
        "        ax.plot([0, grid_size], [i, i], color=\"black\")\n",
        "\n",
        "    # Plot belief about food location using light colored squares\n",
        "    for i in range(num_locations):\n",
        "        belief_prob = float(food_beliefs[i])  # Convert JAX array element to Python float\n",
        "        if belief_prob > 0:  # Only color if there's a non-zero belief\n",
        "            x, y = divmod(i, grid_size)\n",
        "            ax.add_patch(plt.Rectangle((y, grid_size - 1 - x), 1, 1, color=\"yellow\", alpha=belief_prob))\n",
        "            ax.text(y + 0.5, grid_size - 1 - x + 0.5, f'{belief_prob:.2f}', \n",
        "                    ha=\"center\", va=\"center\", fontsize=8, color=\"black\")\n",
        "\n",
        "    # Plot food location\n",
        "    food_x, food_y = divmod(food_location, grid_size)\n",
        "    ax.text(food_y + 0.5, grid_size - food_x - 0.5, 'F', color=\"green\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot traces\n",
        "    for i, trace in enumerate(traces):\n",
        "        if trace > 0:\n",
        "            trace_x, trace_y = divmod(i, grid_size)\n",
        "            ax.text(trace_y + 0.5, grid_size - trace_x - 0.5, 'T', color=\"red\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Plot agent location\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    ax.text(agent_y + 0.5, grid_size - agent_x - 0.5, 'A', color=\"blue\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "\n",
        "    # Remove ticks and labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    # Save frame\n",
        "    plt.title(f\"Timestep {timestep}\")\n",
        "    plt.savefig(f\"{frame_dir}/frame_{timestep}.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Updated Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"self_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "        },\n",
        "        \"food_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            # \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\", \"trace_location_state\"],\n",
        "        },\n",
        "        \"trace_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\",\"trace_location_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"movement\": {\"elements\": movement_actions},\n",
        "        \"trace\": {\"elements\": trace_actions},\n",
        "        \"food_location_action\": {\"elements\": [\"nil\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"self_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "            \"controlled_by\": [\"movement\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"food_location_action\"],\n",
        "        },\n",
        "        \"trace_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"trace_location_state\"],\n",
        "            \"controlled_by\": [\"trace\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "\n",
        "\n",
        "# Set base probabilities for food and trace observations\n",
        "prob_food_and_trace = 1.0  # Probability when both food and trace are present\n",
        "prob_only_food = 1.0       # Probability when only food is present (no trace)\n",
        "prob_only_trace = 0.3      # Slightly higher probability when only trace is present (no food)\n",
        "prob_none = 0.0            # Probability when neither food nor trace is present\n",
        "\n",
        "\n",
        "# Populate A matrices\n",
        "# Self location observation (identity mapping)\n",
        "# for i in range(num_locations):\n",
        "#     model.A[\"self_location\"][i, i] = 1.0\n",
        "\n",
        "# # Food present observation\n",
        "# for self_loc in range(num_locations):\n",
        "#     for food_loc in range(num_locations):\n",
        "#         if self_loc == food_loc:\n",
        "#             model.A[\"food_present\"][0, self_loc, food_loc] = 1.0  # \"yes\"\n",
        "#         else:\n",
        "#             model.A[\"food_present\"][1, self_loc, food_loc] = 1.0  # \"no\"\n",
        "\n",
        "# # Trace present observation\n",
        "# for self_loc in range(num_locations):\n",
        "#     for trace_loc in range(num_locations):\n",
        "#         if self_loc == trace_loc:\n",
        "#             model.A[\"trace_present\"][0, self_loc, trace_loc] = 1.0  # \"yes\"\n",
        "#         else:\n",
        "#             model.A[\"trace_present\"][1, self_loc, trace_loc] = 1.0  # \"no\"\n",
        "\n",
        "# Self location observation (identity mapping, no change here)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"self_location\"][i, i] = 1.0\n",
        "\n",
        "# Food present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        for trace_loc in range(num_locations):\n",
        "            # Case 1: Both food and trace are present at the same location as the agent\n",
        "            if self_loc == food_loc and self_loc == trace_loc:\n",
        "                model.A[\"food_present\"][0, self_loc, food_loc, trace_loc] = prob_food_and_trace  # \"yes\"\n",
        "                model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_food_and_trace  # \"no\"\n",
        "\n",
        "            # Case 2: Only food is present (no trace)\n",
        "            elif self_loc == food_loc and self_loc != trace_loc:\n",
        "                model.A[\"food_present\"][0, self_loc, food_loc, trace_loc] = prob_only_food  # \"yes\"\n",
        "                model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_only_food  # \"no\"\n",
        "\n",
        "            # Case 3: Only trace is present (no food)\n",
        "            elif self_loc != food_loc and self_loc == trace_loc:\n",
        "                model.A[\"food_present\"][0, self_loc, food_loc, trace_loc] = prob_only_trace  # \"yes\" with lower probability\n",
        "                model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_only_trace  # \"no\"\n",
        "                # model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 0.3  # \"no\"\n",
        "\n",
        "            # Case 4: Neither food nor trace is present\n",
        "            else:\n",
        "                model.A[\"food_present\"][0, self_loc, food_loc, trace_loc] = prob_none  # \"yes\"\n",
        "                model.A[\"food_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_none  # \"no\"\n",
        "\n",
        "# Trace present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        for trace_loc in range(num_locations):\n",
        "            # Case 1: Both food and trace are present at the same location as the agent\n",
        "            if self_loc == food_loc and self_loc == trace_loc:\n",
        "                model.A[\"trace_present\"][0, self_loc, food_loc, trace_loc] = prob_food_and_trace  # \"yes\"\n",
        "                model.A[\"trace_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_food_and_trace  # \"no\"\n",
        "\n",
        "            # Case 2: Only trace is present (no food)\n",
        "            elif self_loc != food_loc and self_loc == trace_loc:\n",
        "                model.A[\"trace_present\"][0, self_loc, food_loc, trace_loc] = prob_only_trace  # \"yes\"\n",
        "                model.A[\"trace_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_only_trace  # \"no\"\n",
        "\n",
        "            # Case 3: Only food is present (no trace)\n",
        "            elif self_loc == food_loc and self_loc != trace_loc:\n",
        "                model.A[\"trace_present\"][0, self_loc, food_loc, trace_loc] = prob_only_food  # \"yes\"\n",
        "                model.A[\"trace_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_only_food  # \"no\"\n",
        "\n",
        "            # Case 4: Neither food nor trace is present\n",
        "            else:\n",
        "                model.A[\"trace_present\"][0, self_loc, food_loc, trace_loc] = prob_none  # \"yes\"\n",
        "                model.A[\"trace_present\"][1, self_loc, food_loc, trace_loc] = 1 - prob_none  # \"no\"\n",
        "\n",
        "# print(\"model.A['food_present'][0, :, :, :] yes\", model.A[\"food_present\"][0, :, :, :])\n",
        "# print(\"model.A['food_present'][1, :, :, :] no\", model.A[\"food_present\"][1, :, :, :])\n",
        "# # Populate B matrices\n",
        "# # Self movement\n",
        "# for current_loc in range(num_locations):\n",
        "#     for action_idx, action in enumerate(movement_actions):\n",
        "#         new_loc = get_new_location(current_loc, action, grid_size)\n",
        "#         model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# # Food location (stays constant)\n",
        "# for loc in range(num_locations):\n",
        "#     model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# # Traces update\n",
        "# for current_trace in range(num_locations):\n",
        "#     for self_loc in range(num_locations):\n",
        "#         model.B[\"trace_location_state\"][current_trace, current_trace, self_loc, 0] = 1.0  # Existing trace remains\n",
        "#         model.B[\"trace_location_state\"][self_loc, current_trace, self_loc, 1] = 1.0  # New trace is created\n",
        "\n",
        "\n",
        "# Populate B matrices\n",
        "# Self movement\n",
        "# for current_loc in range(num_locations):\n",
        "#     for action_idx, action in enumerate(movement_actions):\n",
        "#         new_loc = get_new_location(current_loc, action, grid_size)\n",
        "#         model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Populate B matrices for self_location_state (with boundary checks)\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(movement_actions):\n",
        "        # Calculate the new location based on the action\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "\n",
        "        # Check if the action tries to move the agent out of bounds\n",
        "        if new_loc == current_loc:  # No change in location means the move is invalid (out of bounds)\n",
        "            model.B[\"self_location_state\"][current_loc, current_loc, action_idx] = 1.0\n",
        "        else:\n",
        "            model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc] = 1.0\n",
        "\n",
        "# Traces update\n",
        "# Ensuring correct dimensions and indices for the trace_location_state\n",
        "# Traces update\n",
        "for current_trace in range(num_locations):\n",
        "    for self_loc in range(num_locations):\n",
        "        # Leave a new trace at the agent's location\n",
        "        model.B[\"trace_location_state\"][self_loc, current_trace, 1] = 1.0\n",
        "        # Maintain the existing trace\n",
        "        model.B[\"trace_location_state\"][current_trace, current_trace, 0] = 1.0\n",
        "\n",
        "# print(\"model b\", model.B)\n",
        "\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"self_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "# model.C[\"food_present\"] = np.array([1.0, 0.0])  # Prefer food present\n",
        "model.C[\"food_present\"] = np.array([10.0, -10.0])  # Prefer food present\n",
        "model.C[\"trace_present\"] = np.array([0.5, 0.5])  # Neutral about traces\n",
        "\n",
        "model.D[\"self_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "# model.D[\"food_location_state\"] = np.random.randint(num_locations)  # random initial belief\n",
        "model.D[\"trace_location_state\"] = np.zeros(num_locations)  # No traces initially\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(**model, apply_batch=True, policy_len=3)\n",
        "\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "traces = np.zeros(num_locations)\n",
        "\n",
        "print(f\"Agent location: {agent_location}\")\n",
        "print(f\"Food location: {food_location}\")\n",
        "print(f\"Traces: {traces}\")\n",
        "\n",
        "\n",
        "def run_timestep(agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep):\n",
        "    # Generate observations\n",
        "    self_loc_obs = np.zeros(num_locations)\n",
        "    self_loc_obs[agent_location] = 1\n",
        "\n",
        "    food_present_obs = np.zeros(2)\n",
        "    food_present_obs[0 if agent_location == food_location else 1] = 1\n",
        "\n",
        "    trace_present_obs = np.zeros(2)\n",
        "    trace_present_obs[0 if traces[agent_location] > 0 else 1] = 1\n",
        "\n",
        "    observations = [jnp.array(self_loc_obs), jnp.array(food_present_obs), jnp.array(trace_present_obs)]\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    qs_init = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "    # Infer the empirical prior\n",
        "    previous_actions = jnp.array([[movement_actions.index(previous_movement), trace_actions.index(previous_trace), 0]])\n",
        "    print(\"Length of B matrices:\", len(agent.B))  # Should match number of controls (should be 1 if only movement)\n",
        "    print(\"Shape of previous_actions:\", previous_actions.shape)  # Should have one entry for movement action\n",
        "\n",
        "    prior, _ = agent.infer_empirical_prior(previous_actions, qs_init)\n",
        "\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "\n",
        "    # Extract food location beliefs from qs (qs[1] corresponds to food_location_state)\n",
        "    food_beliefs = jnp.squeeze(qs[1][0])\n",
        "    print(\"food beliefs\", food_beliefs)\n",
        "\n",
        "    # Infer policies and sample actions\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    movement_action_index, trace_action_index, _ = agent.sample_action(q_pi)[0]\n",
        "    movement_action = movement_actions[movement_action_index]\n",
        "    trace_action = trace_actions[trace_action_index]\n",
        "\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, movement_action, grid_size)\n",
        "\n",
        "    # Update traces\n",
        "    if trace_action == \"leave_trace\":\n",
        "        traces[agent_location] = 1.0\n",
        "\n",
        "    # Plot the grid for this timestep with beliefs\n",
        "    plot_grid(new_agent_location, food_location, traces, grid_size, timestep, food_beliefs)\n",
        "\n",
        "    return qs, movement_action, trace_action, new_agent_location, traces\n",
        "\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 10\n",
        "previous_movement = \"left\"\n",
        "previous_trace = \"no_trace\"\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, movement_action, trace_action, agent_location, traces = run_timestep(\n",
        "        agent, agent_location, food_location, traces, previous_movement, previous_trace, timestep\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Movement action: {movement_action}\")\n",
        "    print(f\"Trace action: {trace_action}\")\n",
        "    print(f\"Traces: {traces}\")\n",
        "\n",
        "    previous_movement = movement_action\n",
        "    previous_trace = trace_action\n",
        "\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        # break\n",
        "\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")\n",
        "\n",
        "# Create GIF\n",
        "with imageio.get_writer(\"agent_movement.gif\", mode=\"I\", duration=5, loop=0) as writer:\n",
        "    for i in range(num_timesteps):\n",
        "        filename = f\"{frame_dir}/frame_{i}.png\"\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "print(\"GIF saved as 'agent_movement.gif'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.A['food_present'][0, :, :] yes [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "model.A['food_present'][1, :, :] no [[0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 0.]]\n",
            "model B matrix (self_location_state): Distribution({'self_location_state': [0, 1, 2, 3, 4, 5, 6, 7, 8]}, {'self_location_state': [0, 1, 2, 3, 4, 5, 6, 7, 8], 'movement': ['up', 'down', 'left', 'right', 'stay']})\n",
            " [[[1. 0. 1. 0. 1.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 1. 0.]\n",
            "  [1. 0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [1. 0. 0. 1. 1.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 1.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1. 1.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 1. 1. 0. 1.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0. 1.]\n",
            "  [0. 0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 1. 0. 1. 1.]]]\n",
            "model B matrix (food_location_state): Distribution({'food_location_state': [0, 1, 2, 3, 4, 5, 6, 7, 8]}, {'food_location_state': [0, 1, 2, 3, 4, 5, 6, 7, 8], 'food_location_action': ['nil']})\n",
            " [[[1.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [1.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [1.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [1.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [1.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [1.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [1.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [1.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [1.]]]\n",
            "Agent location: 3\n",
            "Food location: 8\n",
            "food beliefs [1.2500000e-01 1.2500000e-01 1.2500000e-01 2.7755625e-17 1.2500000e-01\n",
            " 1.2500000e-01 1.2500000e-01 1.2500000e-01 1.2500000e-01]\n",
            "Observations: [Array([[[0., 0., 0., 1., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[0.22222222, 0.11111111, 0.        , 0.22222222, 0.11111111,\n",
            "        0.        , 0.22222222, 0.11111111, 0.        ]], dtype=float32), Array([[0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
            "        0.11111111, 0.11111111, 0.11111111, 0.11111111]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[2.4532779e-18, 1.2266407e-18, 2.4513135e-33, 1.0000000e+00,\n",
            "         1.2266407e-18, 2.4513135e-33, 2.4532779e-18, 1.2266407e-18,\n",
            "         2.4513135e-33]]], dtype=float32), Array([[[1.2500000e-01, 1.2500000e-01, 1.2500000e-01, 2.7755625e-17,\n",
            "         1.2500000e-01, 1.2500000e-01, 1.2500000e-01, 1.2500000e-01,\n",
            "         1.2500000e-01]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[1.8833626e-02 4.5380206e-05 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  4.5380206e-05 4.5380206e-05 1.0934501e-07 4.5380206e-05 1.0934501e-07\n",
            "  1.8833626e-02 4.5380206e-05 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  1.8833626e-02 4.5380206e-05 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  4.5380206e-05 4.5380206e-05 1.0934501e-07 4.5380206e-05 1.0934501e-07\n",
            "  4.5380206e-05 1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  4.5380206e-05 1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  4.5380206e-05 1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  4.5380206e-05 1.0934501e-07 4.5380206e-05 4.5380206e-05 4.5380206e-05\n",
            "  1.0934501e-07 4.5380206e-05 4.5380206e-05 4.5380206e-05 4.5380206e-05\n",
            "  1.0934501e-07 1.0934501e-07 2.6347044e-10 1.0934501e-07 2.6347044e-10\n",
            "  4.5380206e-05 4.5380206e-05 1.0934501e-07 4.5380206e-05 4.5380206e-05\n",
            "  1.0934501e-07 1.0934501e-07 2.6347044e-10 1.0934501e-07 2.6347044e-10\n",
            "  1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  4.5380206e-05 4.5380206e-05 1.0934501e-07 4.5380206e-05 1.0934501e-07\n",
            "  1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02 1.8833626e-02\n",
            "  1.8833626e-02 1.8833626e-02 4.5380206e-05 1.8833626e-02 1.8833626e-02\n",
            "  4.5380206e-05 1.0934501e-07 4.5380206e-05 4.5380206e-05 4.5380206e-05\n",
            "  1.0934501e-07 4.5380206e-05 4.5380206e-05 4.5380206e-05 4.5380206e-05\n",
            "  1.0934501e-07 1.0934501e-07 2.6347044e-10 1.0934501e-07 2.6347044e-10\n",
            "  4.5380206e-05 4.5380206e-05 1.0934501e-07 4.5380206e-05 4.5380206e-05\n",
            "  1.0934501e-07 1.0934501e-07 2.6347044e-10 1.0934501e-07 2.6347044e-10]]\n",
            "Expected free energy (G): [[1.1303105e+00 7.5354034e-01 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  7.5354034e-01 7.5354034e-01 3.7677017e-01 7.5354034e-01 3.7677017e-01\n",
            "  1.1303105e+00 7.5354034e-01 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  1.1303105e+00 7.5354034e-01 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  7.5354034e-01 7.5354034e-01 3.7677017e-01 7.5354034e-01 3.7677017e-01\n",
            "  7.5354034e-01 1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  7.5354034e-01 1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  7.5354034e-01 1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  7.5354034e-01 3.7677017e-01 7.5354034e-01 7.5354034e-01 7.5354034e-01\n",
            "  3.7677017e-01 7.5354034e-01 7.5354034e-01 7.5354034e-01 7.5354034e-01\n",
            "  3.7677017e-01 3.7677017e-01 4.1631551e-15 3.7677017e-01 4.1631551e-15\n",
            "  7.5354034e-01 7.5354034e-01 3.7677017e-01 7.5354034e-01 7.5354034e-01\n",
            "  3.7677017e-01 3.7677017e-01 4.1631551e-15 3.7677017e-01 4.1631551e-15\n",
            "  1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  7.5354034e-01 7.5354034e-01 3.7677017e-01 7.5354034e-01 3.7677017e-01\n",
            "  1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00 1.1303105e+00\n",
            "  1.1303105e+00 1.1303105e+00 7.5354034e-01 1.1303105e+00 1.1303105e+00\n",
            "  7.5354034e-01 3.7677017e-01 7.5354034e-01 7.5354034e-01 7.5354034e-01\n",
            "  3.7677017e-01 7.5354034e-01 7.5354034e-01 7.5354034e-01 7.5354034e-01\n",
            "  3.7677017e-01 3.7677017e-01 4.2241160e-15 3.7677017e-01 4.2241160e-15\n",
            "  7.5354034e-01 7.5354034e-01 3.7677017e-01 7.5354034e-01 7.5354034e-01\n",
            "  3.7677017e-01 3.7677017e-01 4.2850770e-15 3.7677017e-01 4.3460375e-15]]\n",
            "\n",
            "Timestep 1:\n",
            "Agent location: 4\n",
            "Food location: 8\n",
            "Movement action: right\n",
            "food beliefs [1.4285715e-01 1.4285715e-01 1.4285715e-01 2.5376559e-16 3.1720716e-17\n",
            " 1.4285715e-01 1.4285715e-01 1.4285715e-01 1.4285715e-01]\n",
            "Observations: [Array([[[0., 0., 0., 0., 1., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[0.0000000e+00, 2.4532779e-18, 1.2266407e-18, 0.0000000e+00,\n",
            "        1.0000000e+00, 1.2266407e-18, 0.0000000e+00, 2.4532779e-18,\n",
            "        1.2266407e-18]], dtype=float32), Array([[1.2500000e-01, 1.2500000e-01, 1.2500000e-01, 2.7755625e-17,\n",
            "        1.2500000e-01, 1.2500000e-01, 1.2500000e-01, 1.2500000e-01,\n",
            "        1.2500000e-01]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[2.8619304e-34, 2.8619304e-34, 2.8619304e-34, 4.9303983e-32,\n",
            "         1.0000000e+00, 2.8619304e-34, 2.8619304e-34, 2.8619304e-34,\n",
            "         2.8619304e-34]]], dtype=float32), Array([[[1.4285715e-01, 1.4285715e-01, 1.4285715e-01, 2.5376559e-16,\n",
            "         3.1720716e-17, 1.4285715e-01, 1.4285715e-01, 1.4285715e-01,\n",
            "         1.4285715e-01]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[1.9211434e-02 2.7150565e-05 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  2.7150565e-05 2.7150565e-05 3.8370548e-08 2.7150565e-05 3.8370548e-08\n",
            "  1.9211434e-02 2.7150565e-05 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  1.9211434e-02 2.7150565e-05 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  2.7150565e-05 2.7150565e-05 3.8370548e-08 2.7150565e-05 3.8370548e-08\n",
            "  2.7150565e-05 1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  2.7150565e-05 1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  2.7150565e-05 1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  2.7150565e-05 3.8370548e-08 2.7150565e-05 2.7150565e-05 2.7150565e-05\n",
            "  3.8370548e-08 2.7150565e-05 2.7150565e-05 2.7150565e-05 2.7150565e-05\n",
            "  3.8370548e-08 3.8370548e-08 5.4227196e-11 5.4227196e-11 5.4227196e-11\n",
            "  3.8370548e-08 3.8370548e-08 5.4227196e-11 3.8370548e-08 5.4227196e-11\n",
            "  3.8370548e-08 3.8370548e-08 5.4227196e-11 5.4227196e-11 5.4227196e-11\n",
            "  1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02 1.9211434e-02\n",
            "  2.7150565e-05 2.7150565e-05 3.8370548e-08 2.7150565e-05 3.8370548e-08\n",
            "  1.9211434e-02 1.9211434e-02 2.7150565e-05 1.9211434e-02 1.9211434e-02\n",
            "  1.9211434e-02 1.9211434e-02 2.7150565e-05 1.9211434e-02 1.9211434e-02\n",
            "  2.7150565e-05 3.8370548e-08 2.7150565e-05 2.7150565e-05 2.7150565e-05\n",
            "  3.8370548e-08 2.7150565e-05 2.7150565e-05 2.7150565e-05 2.7150565e-05\n",
            "  3.8370548e-08 3.8370548e-08 5.4227196e-11 5.4227196e-11 5.4227196e-11\n",
            "  2.7150565e-05 2.7150565e-05 3.8370548e-08 2.7150565e-05 2.7150565e-05\n",
            "  3.8370548e-08 3.8370548e-08 5.4227196e-11 3.8370548e-08 5.4227196e-11]]\n",
            "Expected free energy (G): [[ 1.2303489e+00  8.2023251e-01  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  8.2023251e-01  8.2023251e-01  4.1011608e-01\n",
            "   8.2023251e-01  4.1011608e-01  1.2303489e+00  8.2023251e-01\n",
            "   1.2303489e+00  1.2303489e+00  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  1.2303489e+00  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  8.2023251e-01  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  8.2023251e-01  8.2023251e-01  4.1011608e-01\n",
            "   8.2023251e-01  4.1011608e-01  8.2023251e-01  1.2303489e+00\n",
            "   1.2303489e+00  1.2303489e+00  1.2303489e+00  8.2023251e-01\n",
            "   1.2303489e+00  1.2303489e+00  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  1.2303489e+00  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  8.2023251e-01  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  1.2303489e+00  8.2023251e-01  4.1011608e-01\n",
            "   8.2023251e-01  8.2023251e-01  8.2023251e-01  4.1011608e-01\n",
            "   8.2023251e-01  8.2023251e-01  8.2023251e-01  8.2023251e-01\n",
            "   4.1011608e-01  4.1011608e-01 -3.5762784e-07 -3.5762787e-07\n",
            "  -3.5762784e-07  4.1011608e-01  4.1011608e-01 -3.5762787e-07\n",
            "   4.1011608e-01 -3.5762787e-07  4.1011608e-01  4.1011608e-01\n",
            "  -3.5762784e-07 -3.5762787e-07 -3.5762784e-07  1.2303489e+00\n",
            "   1.2303489e+00  1.2303489e+00  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  1.2303489e+00  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  8.2023251e-01  8.2023251e-01  4.1011608e-01\n",
            "   8.2023251e-01  4.1011608e-01  1.2303489e+00  1.2303489e+00\n",
            "   8.2023251e-01  1.2303489e+00  1.2303489e+00  1.2303489e+00\n",
            "   1.2303489e+00  8.2023251e-01  1.2303489e+00  1.2303489e+00\n",
            "   8.2023251e-01  4.1011608e-01  8.2023251e-01  8.2023251e-01\n",
            "   8.2023251e-01  4.1011608e-01  8.2023251e-01  8.2023251e-01\n",
            "   8.2023251e-01  8.2023251e-01  4.1011608e-01  4.1011608e-01\n",
            "  -3.5762787e-07 -3.5762787e-07 -3.5762787e-07  8.2023251e-01\n",
            "   8.2023251e-01  4.1011608e-01  8.2023251e-01  8.2023251e-01\n",
            "   4.1011608e-01  4.1011608e-01 -3.5762787e-07  4.1011608e-01\n",
            "  -3.5762787e-07]]\n",
            "\n",
            "Timestep 2:\n",
            "Agent location: 5\n",
            "Food location: 8\n",
            "Movement action: right\n",
            "food beliefs [1.6666667e-01 1.6666667e-01 1.6666667e-01 2.9605985e-16 2.5905282e-16\n",
            " 3.7007501e-17 1.6666667e-01 1.6666667e-01 1.6666667e-01]\n",
            "Observations: [Array([[[0., 0., 0., 0., 0., 1., 0., 0., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[0.0000000e+00, 2.8619304e-34, 5.7238608e-34, 0.0000000e+00,\n",
            "        4.9303983e-32, 1.0000000e+00, 0.0000000e+00, 2.8619304e-34,\n",
            "        5.7238608e-34]], dtype=float32), Array([[1.4285715e-01, 1.4285715e-01, 1.4285715e-01, 2.5376559e-16,\n",
            "        3.1720716e-17, 1.4285715e-01, 1.4285715e-01, 1.4285715e-01,\n",
            "        1.4285715e-01]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[1.213270e-34, 1.213270e-34, 1.213270e-34, 4.930398e-32,\n",
            "         4.930398e-32, 1.000000e+00, 1.213270e-34, 1.213270e-34,\n",
            "         1.213270e-34]]], dtype=float32), Array([[[1.6666667e-01, 1.6666667e-01, 1.6666667e-01, 2.9605985e-16,\n",
            "         2.5905282e-16, 3.7007501e-17, 1.6666667e-01, 1.6666667e-01,\n",
            "         1.6666667e-01]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[3.1223997e-02 2.3103003e-05 3.1223997e-02 3.1223997e-02 3.1223997e-02\n",
            "  2.3103003e-05 2.3103003e-05 1.7094184e-08 1.7094184e-08 1.7094184e-08\n",
            "  3.1223997e-02 2.3103003e-05 3.1223997e-02 3.1223997e-02 3.1223997e-02\n",
            "  3.1223997e-02 2.3103003e-05 3.1223997e-02 3.1223997e-02 3.1223997e-02\n",
            "  3.1223997e-02 2.3103003e-05 3.1223997e-02 3.1223997e-02 3.1223997e-02\n",
            "  2.3103003e-05 2.3103003e-05 1.7094184e-08 1.7094184e-08 1.7094184e-08\n",
            "  2.3103003e-05 3.1223997e-02 3.1223997e-02 3.1223997e-02 3.1223997e-02\n",
            "  2.3103003e-05 3.1223997e-02 3.1223997e-02 3.1223997e-02 3.1223997e-02\n",
            "  2.3103003e-05 3.1223997e-02 3.1223997e-02 3.1223997e-02 3.1223997e-02\n",
            "  2.3103003e-05 3.1223997e-02 3.1223997e-02 3.1223997e-02 3.1223997e-02\n",
            "  2.3103003e-05 1.7094184e-08 2.3103003e-05 2.3103003e-05 2.3103003e-05\n",
            "  1.7094184e-08 2.3103003e-05 2.3103003e-05 2.3103003e-05 2.3103003e-05\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11\n",
            "  2.3103003e-05 1.7094184e-08 2.3103003e-05 2.3103003e-05 2.3103003e-05\n",
            "  1.7094184e-08 2.3103003e-05 2.3103003e-05 2.3103003e-05 2.3103003e-05\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11\n",
            "  2.3103003e-05 1.7094184e-08 2.3103003e-05 2.3103003e-05 2.3103003e-05\n",
            "  1.7094184e-08 2.3103003e-05 2.3103003e-05 2.3103003e-05 2.3103003e-05\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11\n",
            "  1.7094184e-08 1.7094184e-08 1.2648200e-11 1.2648200e-11 1.2648200e-11]]\n",
            "Expected free energy (G): [[1.3516836e+00 9.0112239e-01 1.3516836e+00 1.3516836e+00 1.3516836e+00\n",
            "  9.0112239e-01 9.0112239e-01 4.5056120e-01 4.5056120e-01 4.5056120e-01\n",
            "  1.3516836e+00 9.0112239e-01 1.3516836e+00 1.3516836e+00 1.3516836e+00\n",
            "  1.3516836e+00 9.0112239e-01 1.3516836e+00 1.3516836e+00 1.3516836e+00\n",
            "  1.3516836e+00 9.0112239e-01 1.3516836e+00 1.3516836e+00 1.3516836e+00\n",
            "  9.0112239e-01 9.0112239e-01 4.5056120e-01 4.5056120e-01 4.5056120e-01\n",
            "  9.0112239e-01 1.3516836e+00 1.3516836e+00 1.3516836e+00 1.3516836e+00\n",
            "  9.0112239e-01 1.3516836e+00 1.3516836e+00 1.3516836e+00 1.3516836e+00\n",
            "  9.0112239e-01 1.3516836e+00 1.3516836e+00 1.3516836e+00 1.3516836e+00\n",
            "  9.0112239e-01 1.3516836e+00 1.3516836e+00 1.3516836e+00 1.3516836e+00\n",
            "  9.0112239e-01 4.5056120e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01\n",
            "  4.5056120e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01\n",
            "  4.5056120e-01 4.5056120e-01 3.0469090e-14 2.9180461e-14 3.0469090e-14\n",
            "  4.5056120e-01 4.5056120e-01 1.9994745e-14 1.2097663e-14 1.2097663e-14\n",
            "  4.5056120e-01 4.5056120e-01 2.9180458e-14 1.9994746e-14 2.7891828e-14\n",
            "  9.0112239e-01 4.5056120e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01\n",
            "  4.5056120e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01\n",
            "  4.5056120e-01 4.5056120e-01 2.1283377e-14 1.2097663e-14 1.9994745e-14\n",
            "  4.5056120e-01 4.5056120e-01 1.2097664e-14 4.2005821e-15 4.2005821e-15\n",
            "  4.5056120e-01 4.5056120e-01 1.2097664e-14 4.2005821e-15 4.2005821e-15\n",
            "  9.0112239e-01 4.5056120e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01\n",
            "  4.5056120e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01 9.0112239e-01\n",
            "  4.5056120e-01 4.5056120e-01 2.1283377e-14 1.2097663e-14 1.9994745e-14\n",
            "  4.5056120e-01 4.5056120e-01 1.2097664e-14 4.2005821e-15 4.2005821e-15\n",
            "  4.5056120e-01 4.5056120e-01 1.2097664e-14 4.2005821e-15 4.2005821e-15]]\n",
            "\n",
            "Timestep 3:\n",
            "Agent location: 2\n",
            "Food location: 8\n",
            "Movement action: up\n",
            "food beliefs [2.0000000e-01 2.0000000e-01 4.4409001e-17 3.5527182e-16 3.1086339e-16\n",
            " 2.6645401e-16 2.0000000e-01 2.0000000e-01 2.0000000e-01]\n",
            "Observations: [Array([[[0., 0., 1., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[4.942531e-32, 4.942531e-32, 1.000000e+00, 1.213270e-34,\n",
            "        1.213270e-34, 1.213270e-34, 0.000000e+00, 0.000000e+00,\n",
            "        0.000000e+00]], dtype=float32), Array([[1.6666667e-01, 1.6666667e-01, 1.6666667e-01, 2.9605985e-16,\n",
            "        2.5905282e-16, 3.7007501e-17, 1.6666667e-01, 1.6666667e-01,\n",
            "        1.6666667e-01]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[3.6489612e-35, 3.6489612e-35, 1.0000000e+00, 4.9303983e-32,\n",
            "         4.9303983e-32, 4.9303983e-32, 3.6489612e-35, 3.6489612e-35,\n",
            "         3.6489612e-35]]], dtype=float32), Array([[[2.0000000e-01, 2.0000000e-01, 4.4409001e-17, 3.5527182e-16,\n",
            "         3.1086339e-16, 2.6645401e-16, 2.0000000e-01, 2.0000000e-01,\n",
            "         2.0000000e-01]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12 3.7003308e-12\n",
            "  3.3307686e-05 1.1101787e-08 3.3307686e-05 1.1101787e-08 3.3307686e-05\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  1.1101787e-08 3.3307686e-05 3.3307686e-05 3.3307686e-05 3.3307686e-05\n",
            "  1.1101787e-08 1.1101787e-08 3.7003308e-12 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12 3.7003308e-12\n",
            "  9.9930018e-02 3.3307686e-05 9.9930018e-02 3.3307686e-05 9.9930018e-02\n",
            "  3.3307686e-05 3.3307686e-05 1.1101787e-08 1.1101787e-08 1.1101787e-08\n",
            "  9.9930018e-02 3.3307686e-05 9.9930018e-02 9.9930018e-02 9.9930018e-02\n",
            "  1.1101787e-08 1.1101787e-08 3.3307686e-05 1.1101787e-08 1.1101787e-08\n",
            "  9.9930018e-02 3.3307686e-05 9.9930018e-02 3.3307686e-05 9.9930018e-02\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12 3.7003308e-12\n",
            "  3.3307686e-05 1.1101787e-08 3.3307686e-05 1.1101787e-08 3.3307686e-05\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12 3.7003308e-12\n",
            "  3.3307686e-05 1.1101787e-08 3.3307686e-05 1.1101787e-08 3.3307686e-05\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12\n",
            "  3.7003308e-12 3.7003308e-12 1.1101787e-08 3.7003308e-12 3.7003308e-12]]\n",
            "Expected free energy (G): [[5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15\n",
            "  1.2899667e-14 5.0040239e-01 2.2327585e-14 2.0782926e-14 2.0782926e-14\n",
            "  1.0008048e+00 5.0040239e-01 1.0008048e+00 5.0040239e-01 1.0008048e+00\n",
            "  5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15\n",
            "  5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15\n",
            "  1.2899667e-14 2.0782926e-14 5.0040239e-01 1.2899667e-14 1.2899667e-14\n",
            "  5.0040239e-01 1.0008048e+00 1.0008048e+00 1.0008048e+00 1.0008048e+00\n",
            "  5.0040239e-01 5.0040239e-01 3.3293765e-14 3.0210843e-14 3.1755502e-14\n",
            "  2.0782926e-14 5.0040239e-01 3.0210843e-14 2.8666183e-14 2.8666183e-14\n",
            "  2.0782926e-14 5.0040239e-01 3.0210843e-14 2.8666183e-14 2.8666183e-14\n",
            "  1.5012071e+00 1.0008048e+00 1.5012071e+00 1.0008048e+00 1.5012071e+00\n",
            "  1.0008048e+00 1.0008048e+00 5.0040239e-01 5.0040239e-01 5.0040239e-01\n",
            "  1.5012071e+00 1.0008048e+00 1.5012071e+00 1.5012071e+00 1.5012071e+00\n",
            "  5.0040239e-01 5.0040239e-01 1.0008048e+00 5.0040239e-01 5.0040239e-01\n",
            "  1.5012071e+00 1.0008048e+00 1.5012071e+00 1.0008048e+00 1.5012071e+00\n",
            "  5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15\n",
            "  1.2899667e-14 5.0040239e-01 2.2327585e-14 2.0782926e-14 2.0782926e-14\n",
            "  1.0008048e+00 5.0040239e-01 1.0008048e+00 5.0040239e-01 1.0008048e+00\n",
            "  5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15\n",
            "  5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15\n",
            "  5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15\n",
            "  1.2899667e-14 5.0040239e-01 2.2327585e-14 2.0782926e-14 2.0782926e-14\n",
            "  1.0008048e+00 5.0040239e-01 1.0008048e+00 5.0040239e-01 1.0008048e+00\n",
            "  5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15\n",
            "  5.0164078e-15 1.2899666e-14 5.0040239e-01 5.0164078e-15 5.0164078e-15]]\n",
            "\n",
            "Timestep 4:\n",
            "Agent location: 1\n",
            "Food location: 8\n",
            "Movement action: left\n",
            "food beliefs [2.5000000e-01 5.5511039e-17 2.7755679e-16 4.4408979e-16 3.8857925e-16\n",
            " 3.3306752e-16 2.5000000e-01 2.5000000e-01 2.5000000e-01]\n",
            "Observations: [Array([[[0., 1., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[7.2979224e-35, 1.0000000e+00, 0.0000000e+00, 9.8607966e-32,\n",
            "        4.9303983e-32, 0.0000000e+00, 7.2979224e-35, 3.6489612e-35,\n",
            "        0.0000000e+00]], dtype=float32), Array([[2.0000000e-01, 2.0000000e-01, 4.4409001e-17, 3.5527182e-16,\n",
            "        3.1086339e-16, 2.6645401e-16, 2.0000000e-01, 2.0000000e-01,\n",
            "        2.0000000e-01]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[6.0185268e-36, 1.0000000e+00, 4.9303983e-32, 4.9303983e-32,\n",
            "         4.9303983e-32, 4.9303983e-32, 6.0185268e-36, 6.0185268e-36,\n",
            "         6.0185268e-36]]], dtype=float32), Array([[[2.5000000e-01, 5.5511039e-17, 2.7755679e-16, 4.4408979e-16,\n",
            "         3.8857925e-16, 3.3306752e-16, 2.5000000e-01, 2.5000000e-01,\n",
            "         2.5000000e-01]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[2.10440741e-13 2.10440741e-13 1.70072678e-09 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.70072678e-09 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.37448287e-05 1.70072678e-09\n",
            "  1.37448287e-05 1.70072678e-09 1.37448287e-05 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.70072678e-09 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 2.10440741e-13 1.70072678e-09\n",
            "  2.10440741e-13 2.10440741e-13 1.70072678e-09 1.37448287e-05\n",
            "  1.37448287e-05 1.37448287e-05 1.37448287e-05 1.70072678e-09\n",
            "  1.70072678e-09 2.10440741e-13 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 1.70072678e-09 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.70072678e-09 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.11082084e-01 1.37448287e-05\n",
            "  1.11082084e-01 1.37448287e-05 1.11082084e-01 1.37448287e-05\n",
            "  1.37448287e-05 1.70072678e-09 1.70072678e-09 1.70072678e-09\n",
            "  1.11082084e-01 1.37448287e-05 1.11082084e-01 1.37448287e-05\n",
            "  1.11082084e-01 1.70072678e-09 1.70072678e-09 1.37448287e-05\n",
            "  1.70072678e-09 1.70072678e-09 1.11082084e-01 1.37448287e-05\n",
            "  1.11082084e-01 1.37448287e-05 1.11082084e-01 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 1.70072678e-09 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 2.10440741e-13 1.70072678e-09\n",
            "  2.10440741e-13 2.10440741e-13 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.70072678e-09 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.70072678e-09 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.37448287e-05 1.70072678e-09\n",
            "  1.37448287e-05 1.70072678e-09 1.37448287e-05 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 2.10440741e-13 2.10440741e-13\n",
            "  2.10440741e-13 2.10440741e-13 1.70072678e-09 2.10440741e-13\n",
            "  2.10440741e-13]]\n",
            "Expected free energy (G): [[6.2333265e-15 1.7943910e-14 5.6233513e-01 1.4097776e-14 6.2333265e-15\n",
            "  1.7943910e-14 5.6233513e-01 3.1564934e-14 2.7736057e-14 2.9654495e-14\n",
            "  1.1246703e+00 5.6233513e-01 1.1246703e+00 5.6233513e-01 1.1246703e+00\n",
            "  2.1962224e-14 2.3889922e-14 1.4097775e-14 2.1962224e-14 2.1962224e-14\n",
            "  6.2333265e-15 1.7943910e-14 5.6233513e-01 1.4097776e-14 6.2333265e-15\n",
            "  1.7943910e-14 2.9654495e-14 5.6233513e-01 2.5808359e-14 1.7943910e-14\n",
            "  5.6233513e-01 1.1246703e+00 1.1246703e+00 1.1246703e+00 1.1246703e+00\n",
            "  5.6233513e-01 5.6233513e-01 4.5185955e-14 4.3275516e-14 4.5185955e-14\n",
            "  3.5600507e-14 5.6233513e-01 3.9446643e-14 3.7528205e-14 3.7528205e-14\n",
            "  2.9654495e-14 5.6233513e-01 4.3275516e-14 3.9446643e-14 4.1365078e-14\n",
            "  1.6870054e+00 1.1246703e+00 1.6870054e+00 1.1246703e+00 1.6870054e+00\n",
            "  1.1246703e+00 1.1246703e+00 5.6233513e-01 5.6233513e-01 5.6233513e-01\n",
            "  1.6870054e+00 1.1246703e+00 1.6870054e+00 1.1246703e+00 1.6870054e+00\n",
            "  5.6233513e-01 5.6233513e-01 1.1246703e+00 5.6233513e-01 5.6233513e-01\n",
            "  1.6870054e+00 1.1246703e+00 1.6870054e+00 1.1246703e+00 1.6870054e+00\n",
            "  2.9826673e-14 3.1754371e-14 2.1962224e-14 2.9826673e-14 2.9826673e-14\n",
            "  3.1754371e-14 5.6233513e-01 3.5600507e-14 3.3682069e-14 3.3682069e-14\n",
            "  1.4097775e-14 2.5808359e-14 5.6233513e-01 2.1962224e-14 1.4097775e-14\n",
            "  2.9826673e-14 3.1754371e-14 2.1962224e-14 2.9826673e-14 2.9826673e-14\n",
            "  2.9826673e-14 3.1754371e-14 2.1962224e-14 2.9826673e-14 2.9826673e-14\n",
            "  6.2333265e-15 1.7943910e-14 5.6233513e-01 1.4097776e-14 6.2333265e-15\n",
            "  1.7943910e-14 5.6233513e-01 3.1564934e-14 2.7736057e-14 2.9654495e-14\n",
            "  1.1246703e+00 5.6233513e-01 1.1246703e+00 5.6233513e-01 1.1246703e+00\n",
            "  2.1962224e-14 2.3889922e-14 1.4097775e-14 2.1962224e-14 2.1962224e-14\n",
            "  6.2333265e-15 1.7943910e-14 5.6233513e-01 1.4097776e-14 6.2333265e-15]]\n",
            "\n",
            "Timestep 5:\n",
            "Agent location: 0\n",
            "Food location: 8\n",
            "Movement action: left\n",
            "food beliefs [7.4015003e-17 2.9606028e-16 3.7007571e-16 5.9211971e-16 5.1810565e-16\n",
            " 4.4409000e-16 3.3333334e-01 3.3333334e-01 3.3333334e-01]\n",
            "Observations: [Array([[[1., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[1.00000000e+00, 4.93039829e-32, 0.00000000e+00, 9.86079658e-32,\n",
            "        4.93039829e-32, 0.00000000e+00, 1.20370535e-35, 6.01852677e-36,\n",
            "        0.00000000e+00]], dtype=float32), Array([[2.5000000e-01, 5.5511039e-17, 2.7755679e-16, 4.4408979e-16,\n",
            "        3.8857925e-16, 3.3306752e-16, 2.5000000e-01, 2.5000000e-01,\n",
            "        2.5000000e-01]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[1.0000000e+00, 4.9303983e-32, 4.9303983e-32, 4.9303983e-32,\n",
            "         4.9303983e-32, 4.9303983e-32, 2.9855859e-37, 2.9855859e-37,\n",
            "         2.9855859e-37]]], dtype=float32), Array([[[7.4015003e-17, 2.9606028e-16, 3.7007571e-16, 5.9211971e-16,\n",
            "         5.1810565e-16, 4.4409000e-16, 3.3333334e-01, 3.3333334e-01,\n",
            "         3.3333334e-01]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 9.4396009e-06 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  9.4396009e-06 2.4998111e-01 2.4998111e-01 2.4998111e-01 2.4998111e-01\n",
            "  3.5645112e-10 9.4396009e-06 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 9.4396009e-06 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 9.4396009e-06 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 9.4396009e-06 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 9.4396009e-06 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 9.4396009e-06 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10\n",
            "  3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10 3.5645112e-10]]\n",
            "Expected free energy (G): [[8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15\n",
            "  2.6259558e-14 6.3651419e-01 4.4271864e-14 4.1745904e-14 4.4271864e-14\n",
            "  8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15\n",
            "  2.3920929e-14 3.1570436e-14 1.6084092e-14 2.6484843e-14 2.3920929e-14\n",
            "  8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15\n",
            "  2.6259558e-14 4.4271864e-14 2.6259558e-14 3.4096396e-14 2.6259558e-14\n",
            "  6.3651419e-01 1.2730284e+00 1.2730284e+00 1.2730284e+00 1.2730284e+00\n",
            "  4.4271864e-14 6.3651419e-01 6.2284169e-14 5.9758208e-14 6.2284169e-14\n",
            "  4.9582744e-14 6.3651419e-01 5.9758208e-14 5.4695628e-14 5.7232254e-14\n",
            "  4.4271864e-14 6.3651419e-01 6.2284169e-14 5.9758208e-14 6.2284169e-14\n",
            "  8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15\n",
            "  2.6259558e-14 6.3651419e-01 4.4271864e-14 4.1745904e-14 4.4271864e-14\n",
            "  8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15\n",
            "  2.3920929e-14 3.1570436e-14 1.6084092e-14 2.6484843e-14 2.3920929e-14\n",
            "  8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15\n",
            "  3.1757766e-14 3.9407273e-14 2.3920929e-14 3.4321680e-14 3.1757766e-14\n",
            "  3.9407276e-14 6.3651419e-01 4.9582741e-14 4.4520160e-14 4.7056783e-14\n",
            "  1.6084092e-14 3.4096396e-14 1.6084092e-14 2.3920929e-14 1.6084092e-14\n",
            "  3.6885595e-14 3.9434564e-14 3.4321680e-14 3.6885595e-14 3.6885595e-14\n",
            "  3.1757766e-14 3.9407273e-14 2.3920929e-14 3.4321680e-14 3.1757766e-14\n",
            "  8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15\n",
            "  2.6259558e-14 6.3651419e-01 4.4271864e-14 4.1745904e-14 4.4271864e-14\n",
            "  8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15\n",
            "  2.3920929e-14 3.1570436e-14 1.6084092e-14 2.6484843e-14 2.3920929e-14\n",
            "  8.2472549e-15 2.6259560e-14 8.2472549e-15 1.6084092e-14 8.2472549e-15]]\n",
            "\n",
            "Timestep 6:\n",
            "Agent location: 3\n",
            "Food location: 8\n",
            "Movement action: down\n",
            "food beliefs [2.2204532e-16 2.9606028e-16 3.7007571e-16 1.3147673e-31 5.1810565e-16\n",
            " 4.4409000e-16 3.3333334e-01 3.3333334e-01 3.3333334e-01]\n",
            "Observations: [Array([[[0., 0., 0., 1., 0., 0., 0., 0., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00,\n",
            "        4.930398e-32, 4.930398e-32, 4.930428e-32, 4.930428e-32,\n",
            "        4.930428e-32]], dtype=float32), Array([[7.4015003e-17, 2.9606028e-16, 3.7007571e-16, 5.9211971e-16,\n",
            "        5.1810565e-16, 4.4409000e-16, 3.3333334e-01, 3.3333334e-01,\n",
            "        3.3333334e-01]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[4.9303983e-32, 4.9303983e-32, 4.9303983e-32, 1.0000000e+00,\n",
            "         4.9303983e-32, 4.9303983e-32, 2.9855859e-37, 2.9855859e-37,\n",
            "         2.9855859e-37]]], dtype=float32), Array([[[2.2204532e-16, 2.9606028e-16, 3.7007571e-16, 1.3147673e-31,\n",
            "         5.1810565e-16, 4.4409000e-16, 3.3333334e-01, 3.3333334e-01,\n",
            "         3.3333334e-01]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  8.9115951e-11 2.3599839e-06 8.9115951e-11 8.9115951e-11 8.9115951e-11\n",
            "  2.3599839e-06 6.2497497e-02 6.2497497e-02 6.2497497e-02 6.2497497e-02\n",
            "  2.3599839e-06 6.2497497e-02 6.2497497e-02 6.2497497e-02 6.2497497e-02\n",
            "  2.3599839e-06 6.2497497e-02 6.2497497e-02 6.2497497e-02 6.2497497e-02\n",
            "  2.3599839e-06 6.2497497e-02 6.2497497e-02 6.2497497e-02 6.2497497e-02\n",
            "  3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  8.9115951e-11 2.3599839e-06 2.3599839e-06 2.3599839e-06 2.3599839e-06\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  8.9115951e-11 2.3599839e-06 2.3599839e-06 2.3599839e-06 2.3599839e-06\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  8.9115951e-11 2.3599839e-06 2.3599839e-06 2.3599839e-06 2.3599839e-06\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15\n",
            "  3.3651300e-15 8.9115951e-11 3.3651300e-15 3.3651300e-15 3.3651300e-15]]\n",
            "Expected free energy (G): [[2.4009972e-14 1.6006648e-14 2.4009972e-14 2.6592569e-14 2.4009972e-14\n",
            "  1.6006648e-14 6.3651419e-01 8.0033238e-15 2.6238753e-14 8.0033238e-15\n",
            "  2.4009972e-14 1.6006648e-14 2.4009972e-14 2.6592569e-14 2.4009972e-14\n",
            "  2.9175169e-14 3.6824676e-14 2.6592569e-14 3.1739083e-14 2.9175169e-14\n",
            "  2.4009972e-14 1.6006648e-14 2.4009972e-14 2.6592569e-14 2.4009972e-14\n",
            "  6.3651419e-01 1.2730284e+00 6.3651419e-01 6.3651419e-01 6.3651419e-01\n",
            "  1.2730284e+00 1.9095426e+00 1.9095426e+00 1.9095426e+00 1.9095426e+00\n",
            "  1.2730284e+00 1.9095426e+00 1.9095426e+00 1.9095426e+00 1.9095426e+00\n",
            "  1.2730284e+00 1.9095426e+00 1.9095426e+00 1.9095426e+00 1.9095426e+00\n",
            "  1.2730284e+00 1.9095426e+00 1.9095426e+00 1.9095426e+00 1.9095426e+00\n",
            "  1.6006648e-14 8.0033238e-15 1.6006648e-14 1.8589246e-14 1.6006648e-14\n",
            "  6.3651419e-01 1.2730284e+00 1.2730284e+00 1.2730284e+00 1.2730284e+00\n",
            "  8.0033238e-15 6.3651419e-01 6.3195395e-29 1.8235430e-14 6.3195395e-29\n",
            "  2.8821353e-14 6.3651419e-01 1.8235430e-14 3.3934237e-14 3.6470860e-14\n",
            "  8.0033238e-15 6.3651419e-01 6.6843732e-29 1.8235430e-14 7.0492069e-29\n",
            "  3.9407276e-14 4.7056783e-14 3.6824676e-14 4.1971187e-14 3.9407276e-14\n",
            "  6.3651419e-01 1.2730284e+00 1.2730284e+00 1.2730284e+00 1.2730284e+00\n",
            "  2.6238753e-14 6.3651419e-01 1.8235430e-14 3.6470860e-14 1.8235430e-14\n",
            "  4.7084075e-14 6.3651419e-01 5.2169667e-14 4.9633044e-14 4.9633044e-14\n",
            "  4.7056783e-14 6.3651419e-01 3.6470860e-14 5.2169667e-14 5.4706290e-14\n",
            "  1.6006648e-14 8.0033238e-15 1.6006648e-14 1.8589246e-14 1.6006648e-14\n",
            "  6.3651419e-01 1.2730284e+00 1.2730284e+00 1.2730284e+00 1.2730284e+00\n",
            "  8.0033238e-15 6.3651419e-01 7.0466274e-29 1.8235430e-14 7.4114611e-29\n",
            "  2.8821353e-14 6.3651419e-01 1.8235430e-14 3.3934237e-14 3.6470860e-14\n",
            "  8.0033238e-15 6.3651419e-01 7.7737153e-29 1.8235430e-14 8.1359695e-29]]\n",
            "\n",
            "Timestep 7:\n",
            "Agent location: 6\n",
            "Food location: 8\n",
            "Movement action: down\n",
            "food beliefs [3.3306799e-16 4.4409043e-16 5.5511358e-16 3.3306799e-16 7.7715850e-16\n",
            " 6.6613503e-16 1.1102250e-16 5.0000000e-01 5.0000000e-01]\n",
            "Observations: [Array([[[0., 0., 0., 0., 0., 0., 1., 0., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[0.000000e+00, 0.000000e+00, 0.000000e+00, 4.930398e-32,\n",
            "        4.930398e-32, 4.930398e-32, 1.000000e+00, 4.930428e-32,\n",
            "        4.930428e-32]], dtype=float32), Array([[2.2204532e-16, 2.9606028e-16, 3.7007571e-16, 1.3147673e-31,\n",
            "        5.1810565e-16, 4.4409000e-16, 3.3333334e-01, 3.3333334e-01,\n",
            "        3.3333334e-01]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[4.930398e-32, 4.930398e-32, 4.930398e-32, 4.930398e-32,\n",
            "         4.930398e-32, 4.930398e-32, 1.000000e+00, 0.000000e+00,\n",
            "         0.000000e+00]]], dtype=float32), Array([[[3.3306799e-16, 4.4409043e-16, 5.5511358e-16, 3.3306799e-16,\n",
            "         7.7715850e-16, 6.6613503e-16, 1.1102250e-16, 5.0000000e-01,\n",
            "         5.0000000e-01]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16\n",
            "  3.5526266e-16 2.3282494e-11 3.5526266e-16 3.5526266e-16 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  2.3282494e-11 1.5258415e-06 2.3282494e-11 1.5258415e-06 1.5258415e-06\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  2.3282494e-11 1.5258415e-06 2.3282494e-11 1.5258415e-06 1.5258415e-06\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  2.3282494e-11 1.5258415e-06 2.3282494e-11 2.3282494e-11 2.3282494e-11\n",
            "  1.5258415e-06 9.9997558e-02 1.5258415e-06 9.9997558e-02 9.9997558e-02\n",
            "  2.3282494e-11 2.3282494e-11 2.3282494e-11 1.5258415e-06 2.3282494e-11\n",
            "  1.5258415e-06 9.9997558e-02 9.9997558e-02 9.9997558e-02 9.9997558e-02\n",
            "  1.5258415e-06 9.9997558e-02 1.5258415e-06 9.9997558e-02 9.9997558e-02\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16\n",
            "  2.3282494e-11 1.5258415e-06 2.3282494e-11 1.5258415e-06 1.5258415e-06\n",
            "  3.5526266e-16 3.5526266e-16 3.5526266e-16 2.3282494e-11 3.5526266e-16]]\n",
            "Expected free energy (G): [[3.5609814e-14 3.5609814e-14 3.5609814e-14 3.9438694e-14 3.5609814e-14\n",
            "  2.7818488e-14 2.0027161e-14 2.0027161e-14 6.9314718e-01 2.0027161e-14\n",
            "  3.5609814e-14 2.7818488e-14 3.5609814e-14 5.0777911e-14 3.5609814e-14\n",
            "  5.4606791e-14 6.9314718e-01 5.0777911e-14 6.2186083e-14 6.5946001e-14\n",
            "  3.5609814e-14 2.7818488e-14 3.5609814e-14 5.0777911e-14 3.5609814e-14\n",
            "  2.7818488e-14 2.0027161e-14 2.7818488e-14 4.2986583e-14 2.7818488e-14\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14\n",
            "  6.9314718e-01 1.3862944e+00 6.9314718e-01 1.3862944e+00 1.3862944e+00\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14\n",
            "  2.7818488e-14 2.0027161e-14 2.7818488e-14 4.2986583e-14 2.7818488e-14\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14\n",
            "  6.9314718e-01 1.3862944e+00 6.9314718e-01 1.3862944e+00 1.3862944e+00\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14\n",
            "  6.9314718e-01 1.3862944e+00 6.9314718e-01 6.9314718e-01 6.9314718e-01\n",
            "  1.3862944e+00 2.0794415e+00 1.3862944e+00 2.0794415e+00 2.0794415e+00\n",
            "  6.9314718e-01 6.9314718e-01 6.9314718e-01 1.3862944e+00 6.9314718e-01\n",
            "  1.3862944e+00 2.0794415e+00 2.0794415e+00 2.0794415e+00 2.0794415e+00\n",
            "  1.3862944e+00 2.0794415e+00 1.3862944e+00 2.0794415e+00 2.0794415e+00\n",
            "  2.7818488e-14 2.0027161e-14 2.7818488e-14 4.2986583e-14 2.7818488e-14\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14\n",
            "  6.9314718e-01 1.3862944e+00 6.9314718e-01 1.3862944e+00 1.3862944e+00\n",
            "  2.0027161e-14 1.2235833e-14 1.2235833e-14 6.9314718e-01 1.2235833e-14]]\n",
            "\n",
            "Timestep 8:\n",
            "Agent location: 7\n",
            "Food location: 8\n",
            "Movement action: right\n",
            "food beliefs [6.6613599e-16 8.8818085e-16 1.1102272e-15 6.6613599e-16 1.5543170e-15\n",
            " 1.3322701e-15 4.4408937e-16 2.2204500e-16 1.0000000e+00]\n",
            "Observations: [Array([[[0., 0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32), Array([[[0., 1.]]], dtype=float32)]\n",
            "Prior: [Array([[0.000000e+00, 4.930398e-32, 9.860797e-32, 0.000000e+00,\n",
            "        4.930398e-32, 9.860797e-32, 0.000000e+00, 1.000000e+00,\n",
            "        0.000000e+00]], dtype=float32), Array([[3.3306799e-16, 4.4409043e-16, 5.5511358e-16, 3.3306799e-16,\n",
            "        7.7715850e-16, 6.6613503e-16, 1.1102250e-16, 5.0000000e-01,\n",
            "        5.0000000e-01]], dtype=float32)]\n",
            "Posterior (qs): [Array([[[4.930398e-32, 4.930398e-32, 4.930398e-32, 4.930398e-32,\n",
            "         4.930398e-32, 4.930398e-32, 4.930398e-32, 1.000000e+00,\n",
            "         0.000000e+00]]], dtype=float32), Array([[[6.6613599e-16, 8.8818085e-16, 1.1102272e-15, 6.6613599e-16,\n",
            "         1.5543170e-15, 1.3322701e-15, 4.4408937e-16, 2.2204500e-16,\n",
            "         1.0000000e+00]]], dtype=float32)]\n",
            "Policy distribution (q_pi): [[0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.008\n",
            "  0.008 0.008 0.008 0.008 0.008]]\n",
            "Expected free energy (G): [[1.1456270e-13 1.3677940e-13 1.0705884e-13 1.2201049e-13 1.1456270e-13\n",
            "  1.1400071e-13 6.9005321e-14 7.6700798e-14 2.8546742e-13 6.9005321e-14\n",
            "  9.9554987e-14 9.1975621e-14 9.9554987e-14 1.2927554e-13 9.9554987e-14\n",
            "  1.3686127e-13 3.2309688e-13 1.5163017e-13 1.4426424e-13 1.4426424e-13\n",
            "  1.3677940e-13 1.1400070e-13 1.2927554e-13 1.5163016e-13 1.5899608e-13\n",
            "  9.1784016e-14 6.9005321e-14 8.4280158e-14 1.0663478e-13 1.1400071e-13\n",
            "  6.9005321e-14 2.4009938e-14 3.1705409e-14 2.4047203e-13 2.4009938e-14\n",
            "  4.6980242e-14 3.9400879e-14 3.9400879e-14 3.1705409e-14 3.9400879e-14\n",
            "  2.7810149e-13 4.5693413e-13 2.4047203e-13 4.5693413e-13 4.5693413e-13\n",
            "  6.9005321e-14 2.4009938e-14 3.1705409e-14 2.4047203e-13 2.4009938e-14\n",
            "  6.2255078e-14 5.4675716e-14 6.2255078e-14 9.1975628e-14 6.2255078e-14\n",
            "  5.4675712e-14 4.7096350e-14 4.7096350e-14 3.9400879e-14 4.7096350e-14\n",
            "  5.4675712e-14 4.7096350e-14 4.7096350e-14 3.9400879e-14 4.7096350e-14\n",
            "  7.6700792e-14 3.1705409e-14 3.9400879e-14 2.4816751e-13 3.1705409e-14\n",
            "  5.4675712e-14 4.7096350e-14 4.7096350e-14 3.9400879e-14 4.7096350e-14\n",
            "  3.0832796e-13 4.9456359e-13 3.2309688e-13 3.1573095e-13 3.1573095e-13\n",
            "  4.9456359e-13 6.7339623e-13 4.5693413e-13 6.7339623e-13 6.7339623e-13\n",
            "  2.8546742e-13 2.4047203e-13 2.4816751e-13 4.5693413e-13 2.4047203e-13\n",
            "  4.9456359e-13 6.7339623e-13 4.5693413e-13 6.7339623e-13 6.7339623e-13\n",
            "  4.9456359e-13 6.7339623e-13 4.5693413e-13 6.7339623e-13 6.7339623e-13\n",
            "  9.1784016e-14 6.9005321e-14 8.4280158e-14 1.0663478e-13 1.1400071e-13\n",
            "  6.9005321e-14 2.4009938e-14 3.1705409e-14 2.4047203e-13 2.4009938e-14\n",
            "  4.6980242e-14 3.9400879e-14 3.9400879e-14 3.1705409e-14 3.9400879e-14\n",
            "  2.7810149e-13 4.5693413e-13 2.4047203e-13 4.5693413e-13 4.5693413e-13\n",
            "  6.9005321e-14 2.4009938e-14 3.1705409e-14 2.4047203e-13 2.4009938e-14]]\n",
            "\n",
            "Timestep 9:\n",
            "Agent location: 4\n",
            "Food location: 8\n",
            "Movement action: up\n",
            "Maximum timesteps reached. Food not found.\n"
          ]
        }
      ],
      "source": [
        "### Now trying with the trace dependency again\n",
        "#### Now plotting the agent's beliefs about where the food is\n",
        "#### Adding an action to stay and preference for food present is really high\n",
        "import numpy as np\n",
        "import jax.tree_util as jtu\n",
        "from jax import numpy as jnp\n",
        "from pymdp.jax.agent import Agent\n",
        "from pymdp.jax.distribution import Distribution, compile_model\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Grid world dimensions\n",
        "grid_size = 3\n",
        "num_locations = grid_size * grid_size\n",
        "# Possible actions\n",
        "movement_actions = [\"up\", \"down\", \"left\", \"right\", \"stay\"]\n",
        "# Directory to save frames\n",
        "frame_dir = \"frames\"\n",
        "if not os.path.exists(frame_dir):\n",
        "    os.makedirs(frame_dir)\n",
        "\n",
        "\n",
        "def get_new_location(current_loc, action, grid_size):\n",
        "    x, y = divmod(current_loc, grid_size)\n",
        "    if action == \"up\":\n",
        "        x = max(0, x - 1)\n",
        "    elif action == \"down\":\n",
        "        x = min(grid_size - 1, x + 1)\n",
        "    elif action == \"left\":\n",
        "        y = max(0, y - 1)\n",
        "    elif action == \"right\":\n",
        "        y = min(grid_size - 1, y + 1)\n",
        "    return x * grid_size + y\n",
        "\n",
        "\n",
        "def plot_grid(agent_location, food_location, grid_size, timestep, food_beliefs):\n",
        "    \"\"\"Plot the grid world, showing the agent, food, and beliefs about food location.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    # Draw grid\n",
        "    for i in range(grid_size + 1):\n",
        "        ax.plot([i, i], [0, grid_size], color=\"black\")\n",
        "        ax.plot([0, grid_size], [i, i], color=\"black\")\n",
        "    # Plot belief about food location using light colored squares\n",
        "    for i in range(num_locations):\n",
        "        belief_prob = float(food_beliefs[i])  # Convert JAX array element to Python float\n",
        "        if belief_prob > 0:  # Only color if there's a non-zero belief\n",
        "            x, y = divmod(i, grid_size)\n",
        "            ax.add_patch(plt.Rectangle((y, grid_size - 1 - x), 1, 1, color=\"yellow\", alpha=belief_prob))\n",
        "            ax.text(\n",
        "                y + 0.5,\n",
        "                grid_size - 1 - x + 0.5,\n",
        "                f\"{belief_prob:.2f}\",\n",
        "                ha=\"center\",\n",
        "                va=\"center\",\n",
        "                fontsize=8,\n",
        "                color=\"black\",\n",
        "            )\n",
        "    # Plot food location\n",
        "    food_x, food_y = divmod(food_location, grid_size)\n",
        "    ax.text(food_y + 0.5, grid_size - food_x - 0.5, \"F\", color=\"green\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "    # Plot agent location\n",
        "    agent_x, agent_y = divmod(agent_location, grid_size)\n",
        "    ax.text(agent_y + 0.5, grid_size - agent_x - 0.5, \"A\", color=\"blue\", ha=\"center\", va=\"center\", fontsize=14)\n",
        "    # Remove ticks and labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    # Save frame\n",
        "    plt.title(f\"Timestep {timestep}\")\n",
        "    plt.savefig(f\"{frame_dir}/frame_{timestep}.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Updated Model description\n",
        "model_description = {\n",
        "    \"observations\": {\n",
        "        \"self_location\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "        },\n",
        "        \"food_present\": {\n",
        "            \"elements\": [\"yes\", \"no\"],\n",
        "            \"depends_on\": [\"self_location_state\", \"food_location_state\"],\n",
        "        },\n",
        "    },\n",
        "    \"controls\": {\n",
        "        \"movement\": {\"elements\": movement_actions},\n",
        "        \"food_location_action\": {\"elements\": [\"nil\"]},\n",
        "    },\n",
        "    \"states\": {\n",
        "        \"self_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"self_location_state\"],\n",
        "            \"controlled_by\": [\"movement\"],\n",
        "        },\n",
        "        \"food_location_state\": {\n",
        "            \"elements\": range(num_locations),\n",
        "            \"depends_on\": [\"food_location_state\"],\n",
        "            \"controlled_by\": [\"food_location_action\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "# Compile the model\n",
        "model = compile_model(model_description)\n",
        "# Populate A matrices\n",
        "# Self location observation (identity mapping)\n",
        "for i in range(num_locations):\n",
        "    model.A[\"self_location\"][i, i] = 1.0\n",
        "# Food present observation\n",
        "for self_loc in range(num_locations):\n",
        "    for food_loc in range(num_locations):\n",
        "        if self_loc == food_loc:\n",
        "            model.A[\"food_present\"][0, self_loc, food_loc] = 1.0  # \"yes\"\n",
        "            model.A[\"food_present\"][1, self_loc, food_loc] = 0.0  # \"no\"\n",
        "        else:\n",
        "            model.A[\"food_present\"][0, self_loc, food_loc] = 0.0  # \"yes\"\n",
        "            model.A[\"food_present\"][1, self_loc, food_loc] = 1.0  # \"no\"\n",
        "print(\"model.A['food_present'][0, :, :] yes\", model.A[\"food_present\"][0, :, :])\n",
        "print(\"model.A['food_present'][1, :, :] no\", model.A[\"food_present\"][1, :, :])\n",
        "# Populate B matrices for self_location_state (with boundary checks)\n",
        "for current_loc in range(num_locations):\n",
        "    for action_idx, action in enumerate(movement_actions):\n",
        "        new_loc = get_new_location(current_loc, action, grid_size)\n",
        "        # Check if the action tries to move the agent out of bounds\n",
        "        if new_loc == current_loc:  # No change in location means the move is invalid (out of bounds)\n",
        "            model.B[\"self_location_state\"][current_loc, current_loc, action_idx] = 1.0\n",
        "        else:\n",
        "            model.B[\"self_location_state\"][new_loc, current_loc, action_idx] = 1.0\n",
        "# Food location (stays constant)\n",
        "for loc in range(num_locations):\n",
        "    model.B[\"food_location_state\"][loc, loc, :] = 1.0\n",
        "print(\"model B matrix (self_location_state):\", model.B[\"self_location_state\"])\n",
        "print(\"model B matrix (food_location_state):\", model.B[\"food_location_state\"])\n",
        "# Initialize C and D matrices (preferences and initial beliefs)\n",
        "model.C[\"self_location\"] = np.ones(num_locations) / num_locations  # Uniform preference\n",
        "model.C[\"food_present\"] = np.array([10.0, -10.0])  # Strong preference for food present\n",
        "model.D[\"self_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "model.D[\"food_location_state\"] = np.ones(num_locations) / num_locations  # Uniform initial belief\n",
        "# Initialize the agent, mark onehot_obs=True as \n",
        "agent = Agent(**model, apply_batch=True, policy_len=3, onehot_obs=True)\n",
        "# Initialize the environment\n",
        "food_location = np.random.randint(num_locations)\n",
        "agent_location = np.random.randint(num_locations)\n",
        "print(f\"Agent location: {agent_location}\")\n",
        "print(f\"Food location: {food_location}\")\n",
        "\n",
        "\n",
        "def run_timestep(agent, qs_prev, agent_location, food_location, timestep):\n",
        "    # Generate observations\n",
        "    self_loc_obs = np.zeros(num_locations)\n",
        "    self_loc_obs[agent_location] = 1\n",
        "    food_present_obs = np.zeros(2)\n",
        "    food_present_obs[0 if agent_location == food_location else 1] = 1\n",
        "    observations = [jnp.array(self_loc_obs), jnp.array(food_present_obs)]\n",
        "    # add batch dim\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "    # add time dim\n",
        "    observations = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), observations)\n",
        "\n",
        "    # Initialize qs (initial beliefs)\n",
        "    # Infer the empirical prior (only considering movement now)\n",
        "    previous_actions = jnp.array([[movement_actions.index(previous_movement), 0]])\n",
        "    prior, _ = agent.infer_empirical_prior(previous_actions, qs_prev)\n",
        "    # Infer states\n",
        "    qs = agent.infer_states(observations, None, prior, None)\n",
        "    # Extract food location beliefs from qs (qs[1] corresponds to food_location_state)\n",
        "    food_beliefs = jnp.squeeze(qs[1][0])\n",
        "    print(\"food beliefs\", food_beliefs)\n",
        "    # Infer policies and sample actions\n",
        "    q_pi, G = agent.infer_policies(qs)\n",
        "    # Sample action: now only a single action (movement), so only one index is returned\n",
        "    movement_action_index = agent.sample_action(q_pi)[0][0]  # Accessing the single movement action\n",
        "    movement_action = movement_actions[movement_action_index]\n",
        "    # Update the agent's location\n",
        "    new_agent_location = get_new_location(agent_location, movement_action, grid_size)\n",
        "    # Plot the grid for this timestep with beliefs\n",
        "    plot_grid(new_agent_location, food_location, grid_size, timestep, food_beliefs)\n",
        "    print(f\"Observations: {observations}\")\n",
        "    print(f\"Prior: {prior}\")\n",
        "    print(f\"Posterior (qs): {qs}\")\n",
        "    print(f\"Policy distribution (q_pi): {q_pi}\")\n",
        "    print(f\"Expected free energy (G): {G}\")\n",
        "    return qs, movement_action, new_agent_location\n",
        "\n",
        "\n",
        "# Simulation loop\n",
        "num_timesteps = 9\n",
        "previous_movement = \"left\"\n",
        "qs = jtu.tree_map(lambda arr: jnp.expand_dims(arr, 0), agent.D)\n",
        "\n",
        "for timestep in range(num_timesteps):\n",
        "    qs, movement_action, agent_location = run_timestep(agent, qs, agent_location, food_location, timestep)\n",
        "    print(f\"\\nTimestep {timestep + 1}:\")\n",
        "    print(f\"Agent location: {agent_location}\")\n",
        "    print(f\"Food location: {food_location}\")\n",
        "    print(f\"Movement action: {movement_action}\")\n",
        "    previous_movement = movement_action\n",
        "    # Check if food is found\n",
        "    if agent_location == food_location:\n",
        "        print(\"Food found!\")\n",
        "        break\n",
        "if timestep == num_timesteps - 1:\n",
        "    print(\"Maximum timesteps reached. Food not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
